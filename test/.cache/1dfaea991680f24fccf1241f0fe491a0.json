{"dependencies":[{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16real/tfjs-core/test/package.json","includedInParent":true,"mtime":1524156395000},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16real/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1524156663000},{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/float16real/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1524152197486},{"name":"./doc","loc":{"line":9,"column":20}},{"name":"./environment","loc":{"line":10,"column":28}},{"name":"./globals","loc":{"line":11,"column":24}},{"name":"./tensor","loc":{"line":12,"column":23}},{"name":"./util","loc":{"line":13,"column":19}}],"generated":{"js":"\"use strict\";\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar doc_1 = require(\"./doc\");\nvar environment_1 = require(\"./environment\");\nvar globals_1 = require(\"./globals\");\nvar tensor_1 = require(\"./tensor\");\nvar util = require(\"./util\");\nvar Gradients = (function () {\n    function Gradients() {\n    }\n    Gradients.gradScope = function (nameOrScopeFn, scopeFn) {\n        return globals_1.tidy(nameOrScopeFn, scopeFn, true);\n    };\n    Gradients.grad = function (f) {\n        util.assert(util.isFunction(f), 'The f passed in grad(f) must be a function');\n        return function (x, dy) {\n            util.assert(x instanceof tensor_1.Tensor, 'The x passed in grad(f)(x) must be a tensor');\n            util.assert(dy == null || dy instanceof tensor_1.Tensor, 'The dy passed in grad(f)(x, dy) must be a tensor');\n            var _a = environment_1.ENV.engine.gradients(function () { return f(x); }, [x], dy), value = _a.value, grads = _a.grads;\n            if (dy != null) {\n                util.assertShapesMatch(value.shape, dy.shape, 'The shape of dy passed in grad(f)(x, dy) must match the shape ' +\n                    'returned by f(x)');\n            }\n            value.dispose();\n            checkGrads(grads);\n            return grads[0];\n        };\n    };\n    Gradients.grads = function (f) {\n        util.assert(util.isFunction(f), 'The f passed in grads(f) must be a function');\n        return function (args, dy) {\n            util.assert(Array.isArray(args) && args.every(function (arg) { return arg instanceof tensor_1.Tensor; }), 'The args passed in grads(f)(args) must be an array of tensors');\n            util.assert(dy == null || dy instanceof tensor_1.Tensor, 'The dy passed in grads(f)(args, dy) must be a tensor');\n            var _a = environment_1.ENV.engine.gradients(function () { return f.apply(void 0, args); }, args, dy), value = _a.value, grads = _a.grads;\n            if (dy != null) {\n                util.assertShapesMatch(value.shape, dy.shape, 'The shape of dy passed in grads(f)([x1,...], dy) must match the ' +\n                    'shape returned by f([x1,...])');\n            }\n            value.dispose();\n            checkGrads(grads);\n            return grads;\n        };\n    };\n    Gradients.valueAndGrad = function (f) {\n        util.assert(util.isFunction(f), 'The f passed in valueAndGrad(f) must be a function');\n        return function (x, dy) {\n            util.assert(x instanceof tensor_1.Tensor, 'The x passed in valueAndGrad(f)(x) must be a tensor');\n            util.assert(dy == null || dy instanceof tensor_1.Tensor, 'The dy passed in valueAndGrad(f)(x, dy) must be a tensor');\n            var _a = environment_1.ENV.engine.gradients(function () { return f(x); }, [x], dy), grads = _a.grads, value = _a.value;\n            checkGrads(grads);\n            return { grad: grads[0], value: value };\n        };\n    };\n    Gradients.valueAndGrads = function (f) {\n        util.assert(util.isFunction(f), 'The f passed in valueAndGrads(f) must be a function');\n        return function (args, dy) {\n            util.assert(Array.isArray(args) && args.every(function (arg) { return arg instanceof tensor_1.Tensor; }), 'The args passed in valueAndGrads(f)(args) must be array of tensors');\n            util.assert(dy == null || dy instanceof tensor_1.Tensor, 'The dy passed in valueAndGrads(f)(args, dy) must be a tensor');\n            var res = environment_1.ENV.engine.gradients(function () { return f.apply(void 0, args); }, args, dy);\n            if (dy != null) {\n                util.assertShapesMatch(res.value.shape, dy.shape, 'The shape of dy passed in valueAndGrads(f)([x1,...], dy) must ' +\n                    'match the shape returned by f([x1,...])');\n            }\n            checkGrads(res.grads);\n            return res;\n        };\n    };\n    Gradients.variableGrads = function (f, varList) {\n        util.assert(util.isFunction(f), 'The f passed in variableGrads(f) must be a function');\n        util.assert(varList == null ||\n            Array.isArray(varList) && varList.every(function (v) { return v instanceof tensor_1.Variable; }), 'The varList passed in variableGrads(f, varList) must be an array ' +\n            'of variables');\n        if (varList == null) {\n            varList = [];\n            for (var varName in environment_1.ENV.engine.registeredVariables) {\n                varList.push(environment_1.ENV.engine.registeredVariables[varName]);\n            }\n        }\n        var originalVarCount = varList.length;\n        varList = varList.filter(function (variable) { return variable.trainable; });\n        util.assert(varList.length > 0, \"variableGrads() expects at least one of the input variables to be \" +\n            (\"trainable, but none of the \" + originalVarCount + \" variables is \") +\n            \"trainable.\");\n        var allowNoGradients = true;\n        var _a = environment_1.ENV.engine.gradients(f, varList, null, allowNoGradients), value = _a.value, grads = _a.grads;\n        util.assert(grads.some(function (g) { return g != null; }), 'Cannot find a connection between any variable and the result of the ' +\n            'loss function y=f(x). Please make sure the operations that use ' +\n            'variables are inside the function f passed to minimize().');\n        util.assert(value.rank === 0, \"The f passed in variableGrads(f) must return a scalar, but it \" +\n            (\"returned a rank-\" + value.rank + \" tensor\"));\n        var namedGrads = {};\n        varList.forEach(function (v, i) {\n            if (grads[i] != null) {\n                namedGrads[v.name] = grads[i];\n            }\n        });\n        return { value: value, grads: namedGrads };\n    };\n    Gradients.customGrad = function (f) {\n        return environment_1.ENV.engine.customGrad(f);\n    };\n    __decorate([\n        doc_1.doc({ heading: 'Training', subheading: 'Gradients' })\n    ], Gradients, \"grad\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Training', subheading: 'Gradients' })\n    ], Gradients, \"grads\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Training', subheading: 'Gradients' })\n    ], Gradients, \"valueAndGrad\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Training', subheading: 'Gradients' })\n    ], Gradients, \"valueAndGrads\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Training', subheading: 'Gradients' })\n    ], Gradients, \"variableGrads\", null);\n    __decorate([\n        doc_1.doc({ heading: 'Training', subheading: 'Gradients' })\n    ], Gradients, \"customGrad\", null);\n    return Gradients;\n}());\nexports.Gradients = Gradients;\nfunction checkGrads(grads) {\n    var numNullGradients = grads.filter(function (g) { return g == null; }).length;\n    if (numNullGradients > 0) {\n        throw new Error(\"Cannot compute gradient of y=f(x) with respect to x. Make sure that\\n    the f you passed encloses all operations that lead from x to y.\");\n    }\n}\n"},"hash":"089b2f702ee356ce062c40efed02052b","cacheData":{"env":{}}}