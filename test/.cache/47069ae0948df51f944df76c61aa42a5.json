{"dependencies":[{"name":"/Users/nsthorat/Code/deeplearnjs-clients/float16/tfjs-core/test/package.json","includedInParent":true,"mtime":1524411533120},{"name":"/Users/nsthorat/Code/deeplearnjs-clients/float16/tfjs-core/test/.babelrc","includedInParent":true,"mtime":1524411533119},{"name":"/Users/nsthorat/Code/deeplearnjs-clients/float16/tfjs-core/tsconfig.json","includedInParent":true,"mtime":1524410852123},{"name":"seedrandom","loc":{"line":38,"column":25}},{"name":"../environment","loc":{"line":39,"column":28}},{"name":"../ops/axis_util","loc":{"line":40,"column":24}},{"name":"../ops/broadcast_util","loc":{"line":41,"column":29}},{"name":"../ops/concat_util","loc":{"line":42,"column":26}},{"name":"../ops/ops","loc":{"line":44,"column":20}},{"name":"../ops/selu_util","loc":{"line":45,"column":24}},{"name":"../ops/erf_util","loc":{"line":46,"column":23}},{"name":"../tensor","loc":{"line":47,"column":23}},{"name":"../types","loc":{"line":48,"column":20}},{"name":"../util","loc":{"line":49,"column":19}},{"name":"./backend_util","loc":{"line":50,"column":27}}],"generated":{"js":"\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar seedrandom = require(\"seedrandom\");\nvar environment_1 = require(\"../environment\");\nvar axis_util = require(\"../ops/axis_util\");\nvar broadcast_util = require(\"../ops/broadcast_util\");\nvar concat_util = require(\"../ops/concat_util\");\nvar ops = require(\"../ops/ops\");\nvar ops_1 = require(\"../ops/ops\");\nvar selu_util = require(\"../ops/selu_util\");\nvar erf_util = require(\"../ops/erf_util\");\nvar tensor_1 = require(\"../tensor\");\nvar types = require(\"../types\");\nvar util = require(\"../util\");\nvar backend_util = require(\"./backend_util\");\nvar MathBackendCPU = (function () {\n    function MathBackendCPU() {\n        this.data = new WeakMap();\n        if (typeof document !== 'undefined') {\n            this.canvas = document.createElement('canvas');\n        }\n    }\n    MathBackendCPU.prototype.register = function (dataId, shape, dtype) {\n        if (this.data.has(dataId)) {\n            throw new Error(\"Data buffer is already registered\");\n        }\n        this.data.set(dataId, null);\n    };\n    MathBackendCPU.prototype.write = function (dataId, values) {\n        if (values == null) {\n            throw new Error('MathBackendCPU.write(): values can not be null');\n        }\n        this.throwIfNoData(dataId);\n        this.data.set(dataId, values);\n    };\n    MathBackendCPU.prototype.fromPixels = function (pixels, numChannels) {\n        if (pixels == null) {\n            throw new Error('MathBackendCPU.writePixels(): pixels can not be null');\n        }\n        var vals;\n        if (pixels instanceof ImageData) {\n            vals = pixels.data;\n        }\n        else if (pixels instanceof HTMLCanvasElement) {\n            vals = pixels.getContext('2d')\n                .getImageData(0, 0, pixels.width, pixels.height)\n                .data;\n        }\n        else if (pixels instanceof HTMLImageElement ||\n            pixels instanceof HTMLVideoElement) {\n            if (this.canvas == null) {\n                throw new Error('Can\\'t read pixels from HTMLImageElement outside ' +\n                    'the browser.');\n            }\n            this.canvas.width = pixels.width;\n            this.canvas.height = pixels.height;\n            this.canvas.getContext('2d').drawImage(pixels, 0, 0, pixels.width, pixels.height);\n            vals = this.canvas.getContext('2d')\n                .getImageData(0, 0, pixels.width, pixels.height)\n                .data;\n        }\n        else {\n            throw new Error(\"pixels is of unknown type: \" + pixels.constructor.name);\n        }\n        var values;\n        if (numChannels === 4) {\n            values = new Int32Array(vals);\n        }\n        else {\n            var numPixels = pixels.width * pixels.height;\n            values = new Int32Array(numPixels * numChannels);\n            for (var i = 0; i < numPixels; i++) {\n                for (var channel = 0; channel < numChannels; ++channel) {\n                    values[i * numChannels + channel] = vals[i * 4 + channel];\n                }\n            }\n        }\n        var outShape = [pixels.height, pixels.width, numChannels];\n        return ops_1.tensor3d(values, outShape, 'int32');\n    };\n    MathBackendCPU.prototype.read = function (dataId) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2, this.readSync(dataId)];\n            });\n        });\n    };\n    MathBackendCPU.prototype.readSync = function (dataId) {\n        this.throwIfNoData(dataId);\n        return this.data.get(dataId);\n    };\n    MathBackendCPU.prototype.disposeData = function (dataId) {\n        if (this.data.has(dataId)) {\n            this.data.delete(dataId);\n        }\n    };\n    MathBackendCPU.prototype.time = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            var start, kernelMs;\n            return __generator(this, function (_a) {\n                start = performance.now();\n                f();\n                kernelMs = performance.now() - start;\n                return [2, { kernelMs: kernelMs }];\n            });\n        });\n    };\n    MathBackendCPU.prototype.memory = function () {\n        return {\n            unreliable: true\n        };\n    };\n    MathBackendCPU.prototype.throwIfNoData = function (dataId) {\n        if (!this.data.has(dataId)) {\n            throw new Error(\"CPU backend: No data found for this tensor. \" +\n                \"Did you change your backend in the middle of the program? \" +\n                \"New backends can't use Tensors created with previous backends\");\n        }\n    };\n    MathBackendCPU.prototype.slice = function (x, begin, size) {\n        var buffer = ops.buffer(size, x.dtype);\n        for (var i = 0; i < buffer.size; ++i) {\n            var loc = buffer.indexToLoc(i);\n            var xLoc = loc.map(function (idx, j) { return idx + begin[j]; });\n            buffer.set.apply(buffer, [x.get.apply(x, xLoc)].concat(loc));\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.reverse = function (x, axis) {\n        var buffer = ops.buffer(x.shape, x.dtype);\n        var xBuffer = x.buffer();\n        var _loop_1 = function (i) {\n            var outLoc = buffer.indexToLoc(i);\n            var inLoc = outLoc.slice();\n            axis.forEach(function (ax) { return inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]; });\n            buffer.set.apply(buffer, [xBuffer.get.apply(xBuffer, inLoc)].concat(outLoc));\n        };\n        for (var i = 0; i < buffer.size; i++) {\n            _loop_1(i);\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.concat = function (a, b) {\n        var outShape = concat_util.computeOutShape(a.shape, b.shape, 1);\n        var buffer = ops.buffer(outShape, a.dtype);\n        if (a.shape[0] === 1 && b.shape[0] === 1) {\n            var aVals = a.dataSync();\n            var bVals = b.dataSync();\n            var vals = buffer.values;\n            vals.set(aVals, 0);\n            vals.set(bVals, a.size);\n            return buffer.toTensor();\n        }\n        for (var i = 0; i < outShape[0]; ++i) {\n            for (var j = 0; j < a.shape[1]; ++j) {\n                buffer.set(a.get(i, j), i, j);\n            }\n            for (var j = 0; j < b.shape[1]; ++j) {\n                buffer.set(b.get(i, j), i, j + a.shape[1]);\n            }\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.neg = function (x) {\n        return this.multiply(ops.scalar(-1), x);\n    };\n    MathBackendCPU.prototype.add = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue + bValue; });\n    };\n    MathBackendCPU.prototype.subtract = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue - bValue; });\n    };\n    MathBackendCPU.prototype.pow = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) { return Math.pow(aValue, bValue); });\n    };\n    MathBackendCPU.prototype.matMul = function (a, b, transposeA, transposeB) {\n        var sharedDim = transposeA ? a.shape[0] : a.shape[1];\n        var leftDim = transposeA ? a.shape[1] : a.shape[0];\n        var rightDim = transposeB ? b.shape[0] : b.shape[1];\n        var aValues = a.dataSync();\n        var bValues = b.dataSync();\n        var _a = transposeA ? [1, a.strides[0]] : [a.strides[0], 1], aOuterStep = _a[0], aInnerStep = _a[1];\n        var _b = transposeB ? [b.strides[0], 1] : [1, b.strides[0]], bOuterStep = _b[0], bInnerStep = _b[1];\n        var aOuterEnd = leftDim * aOuterStep;\n        var bOuterEnd = rightDim * bOuterStep;\n        var result = new Float32Array(leftDim * rightDim);\n        var resultIndex = 0;\n        for (var aOuter = 0; aOuter < aOuterEnd; aOuter += aOuterStep) {\n            for (var bOuter = 0; bOuter < bOuterEnd; bOuter += bOuterStep) {\n                var aInner = aOuter;\n                var bInner = bOuter;\n                var sum = 0;\n                for (var k = 0; k < sharedDim; ++k) {\n                    sum += aValues[aInner] * bValues[bInner];\n                    aInner += aInnerStep;\n                    bInner += bInnerStep;\n                }\n                result[resultIndex++] = sum;\n            }\n        }\n        return ops.tensor2d(result, [leftDim, rightDim]);\n    };\n    MathBackendCPU.prototype.multiply = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue * bValue; });\n    };\n    MathBackendCPU.prototype.divide = function (a, b) {\n        var op;\n        var outputDtype;\n        if (a.dtype === 'int32' && b.dtype === 'int32') {\n            outputDtype = 'int32';\n            op = function (a, b) { return Math.floor(a / b); };\n        }\n        else {\n            outputDtype = 'float32';\n            op = function (a, b) { return a / b; };\n        }\n        return this.broadcastedBinaryOp(a, b, outputDtype, op);\n    };\n    MathBackendCPU.prototype.sum = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var resultDtype = types.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(outShape, resultDtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var sum = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                sum += aVals[offset + j];\n            }\n            vals[i] = sum;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.argMin = function (x, axis) {\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[offset];\n            var minIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value < min) {\n                    min = value;\n                    minIndex = j;\n                }\n            }\n            vals[i] = minIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.argMax = function (x, axis) {\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            var maxIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value > max) {\n                    max = value;\n                    maxIndex = j;\n                }\n            }\n            vals[i] = maxIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.equal = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal === bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.notEqual = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal !== bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.less = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal < bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.lessEqual = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal <= bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.greater = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal > bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.greaterEqual = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal >= bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.logicalNot = function (x) {\n        var values = x.dataSync();\n        var newValues = new Int32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = values[i] ? 0 : 1;\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues }, 'bool');\n    };\n    MathBackendCPU.prototype.logicalAnd = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return aVal && bVal;\n        });\n    };\n    MathBackendCPU.prototype.logicalOr = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return aVal || bVal;\n        });\n    };\n    MathBackendCPU.prototype.where = function (condition, a, b, dtype) {\n        var values = condition.dataSync();\n        var aValues = a.dataSync();\n        var bValues = b.dataSync();\n        var result = ops.zeros(a.shape, dtype);\n        var newValues = result.dataSync();\n        var index = 0;\n        var offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n            1 :\n            a.shape[1];\n        for (var i = 0; i < values.length; i++) {\n            for (var j = 0; j < offset; j++) {\n                if (values[i] === 1) {\n                    newValues[index++] = aValues[i];\n                }\n                else {\n                    newValues[index++] = bValues[i];\n                }\n            }\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.topKValues = function (x, k) {\n        return this.topK(x, k).values;\n    };\n    MathBackendCPU.prototype.topKIndices = function (x, k) {\n        return this.topK(x, k).indices;\n    };\n    MathBackendCPU.prototype.topK = function (x, k) {\n        var values = x.dataSync();\n        var valuesAndIndices = [];\n        for (var i = 0; i < values.length; i++) {\n            valuesAndIndices.push({ value: values[i], index: i });\n        }\n        valuesAndIndices.sort(function (a, b) {\n            return b.value - a.value;\n        });\n        var topkValues = util.getTypedArrayFromDType(x.dtype, k);\n        var topkIndices = new Int32Array(k);\n        for (var i = 0; i < k; i++) {\n            topkValues[i] = valuesAndIndices[i].value;\n            topkIndices[i] = valuesAndIndices[i].index;\n        }\n        return {\n            values: ops.tensor1d(topkValues, x.dtype),\n            indices: ops.tensor1d(topkIndices, 'int32')\n        };\n    };\n    MathBackendCPU.prototype.min = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[0];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value < min) {\n                    min = value;\n                }\n            }\n            vals[i] = min;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.minimum = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.min(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.mod = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n            var rem = aVal % bVal;\n            if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n                return rem;\n            }\n            else {\n                return (rem + bVal) % bVal;\n            }\n        });\n    };\n    MathBackendCPU.prototype.max = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value > max) {\n                    max = value;\n                }\n            }\n            vals[i] = max;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.maximum = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.max(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.squaredDifference = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n            var diff = aVal - bVal;\n            return diff * diff;\n        });\n    };\n    MathBackendCPU.prototype.ceil = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.ceil(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.floor = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.floor(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.sign = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (values[i] < 0) {\n                newValues[i] = -1;\n            }\n            else if (values[i] > 0) {\n                newValues[i] = 1;\n            }\n            else {\n                newValues[i] = 0;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.round = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var base = Math.floor(values[i]);\n            if (values[i] - base < 0.5) {\n                newValues[i] = Math.floor(values[i]);\n            }\n            else if (values[i] - base > 0.5) {\n                newValues[i] = Math.ceil(values[i]);\n            }\n            else {\n                if (base % 2.0 === 0.0) {\n                    newValues[i] = base;\n                }\n                else {\n                    newValues[i] = base + 1.0;\n                }\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.exp = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.exp(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.expm1 = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.expm1(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.log = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.log1p = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log1p(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.sqrt = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.sqrt(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.rsqrt = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = 1 / Math.sqrt(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.square = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = value * value;\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.reciprocal = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = 1 / values[i];\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.relu = function (x) {\n        var res = ops.zeros(x.shape, x.dtype);\n        var resVals = res.dataSync();\n        var inVals = x.dataSync();\n        for (var i = 0; i < inVals.length; ++i) {\n            resVals[i] = Math.max(0, inVals[i]);\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.elu = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = v;\n            }\n            else {\n                resultValues[i] = (Math.exp(v) - 1);\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.eluDer = function (dy, y) {\n        var resultValues = new Float32Array(y.size);\n        var values = y.dataSync();\n        var dyValues = dy.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 1) {\n                resultValues[i] = dyValues[i];\n            }\n            else {\n                resultValues[i] = dyValues[i] * (v + 1);\n            }\n        }\n        return tensor_1.Tensor.make(y.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.selu = function (x) {\n        var scaleAlpha = selu_util.SELU_SCALEALPHA;\n        var scale = selu_util.SELU_SCALE;\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = scale * v;\n            }\n            else {\n                resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.clip = function (x, min, max) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.min(max, Math.max(min, values[i]));\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.abs = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.abs(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.int = function (x) {\n        var resultValues = new Int32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = values[i];\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues }, 'int32');\n    };\n    MathBackendCPU.prototype.sigmoid = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.softplus = function (x) {\n        var epsilon = 1.1920928955078125e-7;\n        var threshold = Math.log(epsilon) + 2.0;\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var tooLarge = values[i] > -threshold;\n            var tooSmall = values[i] < threshold;\n            var expX = Math.exp(values[i]);\n            var result = void 0;\n            if (tooSmall) {\n                result = expX;\n            }\n            else if (tooLarge) {\n                result = values[i];\n            }\n            else {\n                result = Math.log(1.0 + expX);\n            }\n            resultValues[i] = result;\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.sin = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sin(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.cos = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cos(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.tan = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.tan(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.asin = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.asin(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.acos = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.acos(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.atan = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.atan(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.atan2 = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) { return Math.atan2(aValue, bValue); });\n    };\n    MathBackendCPU.prototype.sinh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sinh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.cosh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cosh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.tanh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = util.tanh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.asinh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.asinh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.acosh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.acosh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.atanh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.atanh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.erf = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        var p = erf_util.ERF_P;\n        var a1 = erf_util.ERF_A1;\n        var a2 = erf_util.ERF_A2;\n        var a3 = erf_util.ERF_A3;\n        var a4 = erf_util.ERF_A4;\n        var a5 = erf_util.ERF_A5;\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            var t = 1.0 / (1.0 + p * v);\n            resultValues[i]\n                = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-v * v);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.step = function (x, alpha) {\n        if (alpha === void 0) { alpha = 0; }\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            if (isNaN(value)) {\n                resultValues[i] = NaN;\n            }\n            else {\n                resultValues[i] = value > 0 ? 1 : alpha;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.conv2d = function (x, filter, convInfo) {\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * convInfo.strideHeight - padLeft;\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * convInfo.strideWidth - padTop;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < filterHeight; wR++) {\n                            var xR = xRCorner + wR * dilationHeight;\n                            if (xR < 0 || xR >= convInfo.inHeight) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < filterWidth; wC++) {\n                                var xC = xCCorner + wC * dilationWidth;\n                                if (xC < 0 || xC >= convInfo.inWidth) {\n                                    continue;\n                                }\n                                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                    var pixel = x.get(b, xR, xC, d1);\n                                    var weight = filter.get(wR, wC, d1, d2);\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        y.set(dotProd, b, yR, yC, d2);\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        var dxValues = dx.values;\n        var _a = dx.strides, dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2];\n        var dyValues = dy.dataSync();\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2];\n        var fltValues = filter.dataSync();\n        var _c = filter.strides, fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2];\n        var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var d1 = 0; d1 < inChannels; ++d1) {\n                for (var xR = 0; xR < inHeight; ++xR) {\n                    var xRCorner = xR - leftPad;\n                    var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                    var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                    for (var xC = 0; xC < inWidth; ++xC) {\n                        var xCCorner = xC - topPad;\n                        var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                        var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                        var dotProd = 0;\n                        for (var yR = xRMin; yR < yRMax; ++yR) {\n                            var wR = yR * strideHeight - xRCorner;\n                            for (var yC = xCMin; yC < yCMax; ++yC) {\n                                var wC = yC * strideWidth - xCCorner;\n                                var dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                                var fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                    fltS1 * (filterWidth - 1 - wC) +\n                                    fltS2 * d1;\n                                for (var d2 = 0; d2 < outChannels; ++d2) {\n                                    var pixel = dyValues[dyOffset + d2];\n                                    var weight = fltValues[fltOffset + d2];\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerFilter = function (x, dy, convInfo) {\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dW = ops.buffer(convInfo.filterShape, 'float32');\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        for (var wR = 0; wR < filterHeight; ++wR) {\n            var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n            var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n            for (var wC = 0; wC < filterWidth; ++wC) {\n                var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                        var dotProd = 0;\n                        for (var b = 0; b < convInfo.batchSize; ++b) {\n                            for (var yR = yRMin; yR < yRMax; ++yR) {\n                                var xR = wR + yR * strideHeight - topPad;\n                                for (var yC = yCMin; yC < yCMax; ++yC) {\n                                    var xC = wC + yC * strideWidth - leftPad;\n                                    dotProd += x.get(b, xR, xC, d1) * dy.get(b, yR, yC, d2);\n                                }\n                            }\n                        }\n                        dW.set(dotProd, wR, wC, d1, d2);\n                    }\n                }\n            }\n        }\n        return dW.toTensor();\n    };\n    MathBackendCPU.prototype.depthwiseConv2D = function (x, filter, convInfo) {\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var chMul = convInfo.outChannels / convInfo.inChannels;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * convInfo.strideHeight - padLeft;\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * convInfo.strideWidth - padTop;\n                        for (var q = 0; q < chMul; ++q) {\n                            var dotProd = 0;\n                            for (var wR = 0; wR < filterHeight; ++wR) {\n                                var xR = xRCorner + wR * dilationHeight;\n                                if (xR < 0 || xR >= convInfo.inHeight) {\n                                    continue;\n                                }\n                                for (var wC = 0; wC < filterWidth; ++wC) {\n                                    var xC = xCCorner + wC * dilationWidth;\n                                    if (xC < 0 || xC >= convInfo.inWidth) {\n                                        continue;\n                                    }\n                                    var pixel = x.get(b, xR, xC, d1);\n                                    var weight = filter.get(wR, wC, d1, q);\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                            y.set(dotProd, b, yR, yC, d1 * chMul + q);\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.tile = function (x, reps) {\n        var newShape = new Array(x.rank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = x.shape[i] * reps[i];\n        }\n        var result = ops.buffer(newShape, x.dtype);\n        var xBuf = x.buffer();\n        for (var i = 0; i < result.values.length; ++i) {\n            var newLoc = result.indexToLoc(i);\n            var originalLoc = new Array(x.rank);\n            for (var i_1 = 0; i_1 < originalLoc.length; i_1++) {\n                originalLoc[i_1] = newLoc[i_1] % x.shape[i_1];\n            }\n            var originalIndex = xBuf.locToIndex(originalLoc);\n            result.values[i] = xBuf.values[originalIndex];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.pad = function (x, paddings, constantValue) {\n        var outShape = paddings.map(function (p, i) { return p[0] + x.shape[i] + p[1]; });\n        var start = paddings.map(function (p) { return p[0]; });\n        var xBuffer = x.buffer();\n        var buffer = ops.buffer(outShape, x.dtype);\n        if (constantValue !== 0) {\n            buffer.values.fill(constantValue);\n        }\n        for (var i = 0; i < x.size; i++) {\n            var coords = xBuffer.indexToLoc(i);\n            var outCoords = coords.map(function (c, i) { return c + start[i]; });\n            buffer.set.apply(buffer, [x.get.apply(x, coords)].concat(outCoords));\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.transpose = function (x, perm) {\n        var newShape = new Array(x.rank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = x.shape[perm[i]];\n        }\n        var values = x.dataSync();\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = x.buffer();\n        for (var i = 0; i < x.size; ++i) {\n            var loc = xBuf.indexToLoc(i);\n            var newLoc = new Array(loc.length);\n            for (var i_2 = 0; i_2 < newLoc.length; i_2++) {\n                newLoc[i_2] = loc[perm[i_2]];\n            }\n            var newIndex = result.locToIndex(newLoc);\n            result.values[newIndex] = values[i];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.gather = function (x, indices, axis) {\n        var newShape = x.shape.slice();\n        var indicesValues = indices.dataSync();\n        newShape[axis] = indicesValues.length;\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = x.buffer();\n        for (var i = 0; i < result.size; ++i) {\n            var newLoc = result.indexToLoc(i);\n            var originalLoc = newLoc.slice();\n            originalLoc[axis] = indicesValues[newLoc[axis]];\n            var originalIndex = xBuf.locToIndex(originalLoc);\n            result.values[i] = xBuf.values[originalIndex];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.pool = function (x, convInfo, poolType) {\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var y = ops.buffer(convInfo.outShape, 'float32');\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = Math.max(0, xCCorner);\n                        var xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n                        var minMaxValue = (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n                        var avgValue = 0;\n                        var count = 0;\n                        for (var xR = xRMin; xR < xRMax; ++xR) {\n                            for (var xC = xCMin; xC < xCMax; ++xC) {\n                                var pixel = x.get(b, xR, xC, d);\n                                if ((poolType === 'max' && pixel > minMaxValue)) {\n                                    minMaxValue = pixel;\n                                }\n                                else if (poolType === 'avg') {\n                                    avgValue += pixel;\n                                    count++;\n                                }\n                            }\n                            if (isNaN(minMaxValue)) {\n                                break;\n                            }\n                        }\n                        y.set(poolType === 'avg' ? avgValue / count : minMaxValue, b, yR, yC, d);\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.maxPool = function (x, convInfo) {\n        return this.pool(x, convInfo, 'max');\n    };\n    MathBackendCPU.prototype.maxPoolPositions = function (x, convInfo) {\n        var maxPositions = ops.buffer(convInfo.outShape, 'int32');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = Math.max(0, xCCorner);\n                        var xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n                        var maxValue = Number.NEGATIVE_INFINITY;\n                        var maxPosition = -1;\n                        for (var xR = xRMin; xR < xRMax; ++xR) {\n                            var wR = xR - xRCorner;\n                            for (var xC = xCMin; xC < xCMax; ++xC) {\n                                var wC = xC - xCCorner;\n                                var pixel = x.get(b, xR, xC, d);\n                                if (pixel > maxValue) {\n                                    maxValue = pixel;\n                                    maxPosition = wR * filterWidth + wC;\n                                }\n                            }\n                        }\n                        maxPositions.set(maxPosition, b, yR, yC, d);\n                    }\n                }\n            }\n        }\n        return maxPositions.toTensor();\n    };\n    MathBackendCPU.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n        var maxPositions = this.maxPoolPositions(x, convInfo);\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < filterHeight; ++wR) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < filterWidth; ++wC) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var maxPos = filterHeight * filterWidth - 1 -\n                                    maxPositions.get(b, dyR, dyC, d);\n                                var curPos = wR * filterWidth + wC;\n                                var mask = maxPos === curPos ? 1 : 0;\n                                if (mask === 0) {\n                                    continue;\n                                }\n                                var pixel = dy.get(b, dyR, dyC, d);\n                                dotProd += pixel * mask;\n                            }\n                        }\n                        dx.set(dotProd, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var avgMultiplier = 1 / (filterHeight * filterWidth);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < filterHeight; ++wR) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < filterWidth; ++wC) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var pixel = dy.get(b, dyR, dyC, d);\n                                dotProd += pixel;\n                            }\n                        }\n                        dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.cast = function (x, dtype) {\n        return backend_util.castTensor(x, dtype, this);\n    };\n    MathBackendCPU.prototype.reshape = function (x, shape) {\n        return backend_util.reshapeTensor(x, shape);\n    };\n    MathBackendCPU.prototype.avgPool = function (x, convInfo) {\n        return this.pool(x, convInfo, 'avg').toFloat();\n    };\n    MathBackendCPU.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        var _a = x.shape, batch = _a[0], oldHeight = _a[1], oldWidth = _a[2], numChannels = _a[3];\n        var output = ops.buffer([batch, newHeight, newWidth, numChannels], x.dtype);\n        var effectiveInputSize = alignCorners ? [oldHeight - 1, oldWidth - 1] : [oldHeight, oldWidth];\n        var effectiveOutputSize = alignCorners ? [newHeight - 1, newWidth - 1] : [newHeight, newWidth];\n        for (var b = 0; b < batch; b++) {\n            for (var r = 0; r < newHeight; r++) {\n                for (var c = 0; c < newWidth; c++) {\n                    for (var d = 0; d < numChannels; d++) {\n                        var sourceFracRow = (effectiveInputSize[0]) * r / (effectiveOutputSize[0]);\n                        var sourceFracCol = (effectiveInputSize[1]) * c / (effectiveOutputSize[1]);\n                        var sourceRowFloor = Math.floor(sourceFracRow);\n                        var sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n                        var sourceColFloor = Math.floor(sourceFracCol);\n                        var sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n                        var topLeft = x.get(b, sourceRowFloor, sourceColFloor, d);\n                        var bottomLeft = x.get(b, sourceRowCeil, sourceColFloor, d);\n                        var topRight = x.get(b, sourceRowFloor, sourceColCeil, d);\n                        var bottomRight = x.get(b, sourceRowCeil, sourceColCeil, d);\n                        var rowFrac = sourceFracRow - sourceRowFloor;\n                        var colFrac = sourceFracCol - sourceColFloor;\n                        var top = topLeft + (topRight - topLeft) * colFrac;\n                        var bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n                        var newValue = top + (bottom - top) * rowFrac;\n                        output.set(newValue, b, r, c, d);\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.resizeNearestNeighbor = function (x, newHeight, newWidth, alignCorners) {\n        var _a = x.shape, batch = _a[0], oldHeight = _a[1], oldWidth = _a[2], numChannels = _a[3];\n        var output = ops.buffer([batch, newHeight, newWidth, numChannels], x.dtype);\n        var effectiveInputSize = alignCorners ? [oldHeight - 1, oldWidth - 1] : [oldHeight, oldWidth];\n        var effectiveOutputSize = alignCorners ? [newHeight - 1, newWidth - 1] : [newHeight, newWidth];\n        for (var b = 0; b < batch; b++) {\n            for (var r = 0; r < newHeight; r++) {\n                for (var c = 0; c < newWidth; c++) {\n                    for (var d = 0; d < numChannels; d++) {\n                        var sourceFracRow = (effectiveInputSize[0]) * r / (effectiveOutputSize[0]);\n                        var sourceFracCol = (effectiveInputSize[1]) * c / (effectiveOutputSize[1]);\n                        var sourceNearestRow = Math.min(oldHeight - 1, alignCorners\n                            ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));\n                        var sourceNearestCol = Math.min(oldWidth - 1, alignCorners\n                            ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));\n                        var newValue = x.get(b, sourceNearestRow, sourceNearestCol, d);\n                        output.set(newValue, b, r, c, d);\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        var xValues = x.dataSync();\n        var meanValues = mean.dataSync();\n        var varianceValues = variance.dataSync();\n        var scaleValues = scale ? scale.dataSync() : new Float32Array([1]);\n        var offsetValues = offset ? offset.dataSync() : new Float32Array([0]);\n        var outValues = new Float32Array(xValues.length);\n        for (var i = 0; i < xValues.length; i++) {\n            outValues[i] = offsetValues[i % offsetValues.length] +\n                (xValues[i] - meanValues[i % meanValues.length]) *\n                    scaleValues[i % scaleValues.length] /\n                    Math.sqrt(varianceValues[i % varianceValues.length] + varianceEpsilon);\n        }\n        return ops_1.tensor4d(outValues, x.shape);\n    };\n    MathBackendCPU.prototype.localResponseNormalization4D = function (x, radius, bias, alpha, beta) {\n        var output = ops.buffer(x.shape, 'float32');\n        var rad = radius;\n        var maxD = output.shape[3] - 1;\n        function sumAcrossChannels(b, r, c, d) {\n            var sum = 0.0;\n            for (var j = Math.max(0, d - rad); j <= Math.min(d + rad, maxD); j++) {\n                var z = x.get(b, r, c, j);\n                sum += z * z;\n            }\n            return sum;\n        }\n        for (var b = 0; b < output.shape[0]; b++) {\n            for (var r = 0; r <= output.shape[1]; r++) {\n                for (var c = 0; c < output.shape[2]; c++) {\n                    for (var d = 0; d < output.shape[3]; d++) {\n                        var sum = sumAcrossChannels(b, r, c, d);\n                        var val = x.get(b, r, c, d) * Math.pow(bias + alpha * sum, -beta);\n                        output.set(val, b, r, c, d);\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n        var probabilities = normalized ? logits : ops.softmax(logits);\n        var batchSize = probabilities.shape[0];\n        var numEvents = probabilities.shape[1];\n        var res = ops.zeros([batchSize, numSamples], 'int32');\n        var resVals = res.dataSync();\n        var probVals = probabilities.dataSync();\n        for (var b = 0; b < batchSize; ++b) {\n            var offset = b * numEvents;\n            var cdf = new Float32Array(numEvents - 1);\n            cdf[0] = probVals[offset];\n            for (var event = 1; event < cdf.length; ++event) {\n                cdf[event] = cdf[event - 1] + probVals[offset + event];\n            }\n            var random = seedrandom.alea(seed.toString());\n            var outOffset = b * numSamples;\n            for (var sampleId = 0; sampleId < numSamples; ++sampleId) {\n                var r = random();\n                resVals[outOffset + sampleId] = cdf.length;\n                for (var event = 0; event < cdf.length; event++) {\n                    if (r < cdf[event]) {\n                        resVals[outOffset + sampleId] = event;\n                        break;\n                    }\n                }\n            }\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        var res = new Float32Array(indices.size * depth);\n        res.fill(offValue);\n        for (var event = 0; event < indices.size; ++event) {\n            res[event * depth + indices.get(event)] = onValue;\n        }\n        return ops.tensor2d(res, [indices.size, depth]);\n    };\n    MathBackendCPU.prototype.broadcastedBinaryOp = function (a, b, dtype, op) {\n        var newShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n        var result = ops.buffer(newShape, dtype);\n        var aValues = a.dataSync();\n        var bValues = b.dataSync();\n        var aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n        var bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n        var aBuf = a.buffer();\n        var bBuf = b.buffer();\n        var _loop_2 = function (i) {\n            var loc = result.indexToLoc(i);\n            var aLoc = loc.slice(-a.rank);\n            aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n            var aIndex = aBuf.locToIndex(aLoc);\n            var bLoc = loc.slice(-b.rank);\n            bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n            var bIndex = bBuf.locToIndex(bLoc);\n            result.values[i] = op(aValues[aIndex], bValues[bIndex]);\n        };\n        for (var i = 0; i < result.values.length; ++i) {\n            _loop_2(i);\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.dispose = function () { };\n    return MathBackendCPU;\n}());\nexports.MathBackendCPU = MathBackendCPU;\nenvironment_1.ENV.registerBackend('cpu', function () { return new MathBackendCPU(); }, 1);\n","map":{"version":3,"file":"backend_cpu.js","sourceRoot":"","sources":["../src/kernels/backend_cpu.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,uCAAyC;AAEzC,8CAAmC;AACnC,4CAA8C;AAC9C,sDAAwD;AACxD,gDAAkD;AAElD,gCAAkC;AAClC,kCAAsD;AACtD,4CAA8C;AAC9C,0CAA4C;AAE5C,oCAAiF;AACjF,gCAAkC;AAElC,8BAAgC;AAGhC,6CAA+C;AAE/C;IAIE;QAHQ,SAAI,GAAG,IAAI,OAAO,EAAiC,CAAC;QAI1D,IAAI,OAAO,QAAQ,KAAK,WAAW,EAAE;YACnC,IAAI,CAAC,MAAM,GAAG,QAAQ,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;SAChD;IACH,CAAC;IAED,iCAAQ,GAAR,UAAS,MAAc,EAAE,KAAe,EAAE,KAAe;QACvD,IAAI,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;YACzB,MAAM,IAAI,KAAK,CAAC,mCAAmC,CAAC,CAAC;SACtD;QACD,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;IAC9B,CAAC;IACD,8BAAK,GAAL,UAAM,MAAc,EAAE,MAAkB;QACtC,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,MAAM,IAAI,KAAK,CAAC,gDAAgD,CAAC,CAAC;SACnE;QACD,IAAI,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QAC3B,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;IAChC,CAAC;IACD,mCAAU,GAAV,UACI,MAAqE,EACrE,WAAmB;QACrB,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,MAAM,IAAI,KAAK,CAAC,sDAAsD,CAAC,CAAC;SACzE;QACD,IAAI,IAAuB,CAAC;QAC5B,IAAI,MAAM,YAAY,SAAS,EAAE;YAC/B,IAAI,GAAG,MAAM,CAAC,IAAI,CAAC;SACpB;aAAM,IAAI,MAAM,YAAY,iBAAiB,EAAE;YAC9C,IAAI,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC;iBAClB,YAAY,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC;iBAC/C,IAAI,CAAC;SAClB;aAAM,IACH,MAAM,YAAY,gBAAgB;YAClC,MAAM,YAAY,gBAAgB,EAAE;YACtC,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,EAAE;gBACvB,MAAM,IAAI,KAAK,CACX,mDAAmD;oBACnD,cAAc,CAAC,CAAC;aACrB;YACD,IAAI,CAAC,MAAM,CAAC,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC;YACjC,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC;YACnC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC,SAAS,CAClC,MAAM,EAAE,CAAC,EAAE,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;YAC/C,IAAI,GAAG,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC;iBACvB,YAAY,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC;iBAC/C,IAAI,CAAC;SAClB;aAAM;YACL,MAAM,IAAI,KAAK,CACX,gCAA+B,MAAa,CAAC,WAAW,CAAC,IAAM,CAAC,CAAC;SACtE;QACD,IAAI,MAAkB,CAAC;QACvB,IAAI,WAAW,KAAK,CAAC,EAAE;YACrB,MAAM,GAAG,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC;SAC/B;aAAM;YACL,IAAM,SAAS,GAAG,MAAM,CAAC,KAAK,GAAG,MAAM,CAAC,MAAM,CAAC;YAC/C,MAAM,GAAG,IAAI,UAAU,CAAC,SAAS,GAAG,WAAW,CAAC,CAAC;YACjD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;gBAClC,KAAK,IAAI,OAAO,GAAG,CAAC,EAAE,OAAO,GAAG,WAAW,EAAE,EAAE,OAAO,EAAE;oBACtD,MAAM,CAAC,CAAC,GAAG,WAAW,GAAG,OAAO,CAAC,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,OAAO,CAAC,CAAC;iBAC3D;aACF;SACF;QACD,IAAM,QAAQ,GACV,CAAC,MAAM,CAAC,MAAM,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QAC/C,OAAO,cAAQ,CAAC,MAAM,EAAE,QAAQ,EAAE,OAAO,CAAC,CAAC;IAC7C,CAAC;IACK,6BAAI,GAAV,UAAW,MAAc;;;gBACvB,WAAO,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,EAAC;;;KAC9B;IACD,iCAAQ,GAAR,UAAS,MAAc;QACrB,IAAI,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;IAC/B,CAAC;IAED,oCAAW,GAAX,UAAY,MAAc;QACxB,IAAI,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;YACzB,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;SAC1B;IACH,CAAC;IAEK,6BAAI,GAAV,UAAW,CAAa;;;;gBAChB,KAAK,GAAG,WAAW,CAAC,GAAG,EAAE,CAAC;gBAChC,CAAC,EAAE,CAAC;gBACE,QAAQ,GAAG,WAAW,CAAC,GAAG,EAAE,GAAG,KAAK,CAAC;gBAC3C,WAAO,EAAC,QAAQ,UAAA,EAAC,EAAC;;;KACnB;IACD,+BAAM,GAAN;QACE,OAAO;YAEL,UAAU,EAAE,IAAI;SACjB,CAAC;IACJ,CAAC;IAEO,sCAAa,GAArB,UAAsB,MAAc;QAClC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;YAC1B,MAAM,IAAI,KAAK,CACX,8CAA8C;gBAC9C,4DAA4D;gBAC5D,+DAA+D,CAAC,CAAC;SACtE;IACH,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI,EAAE,KAAe,EAAE,IAAc;QAC3D,IAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAEzC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE;YACpC,IAAM,GAAG,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YACjC,IAAM,IAAI,GAAG,GAAG,CAAC,GAAG,CAAC,UAAC,GAAG,EAAE,CAAC,IAAK,OAAA,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,EAAd,CAAc,CAAC,CAAC;YACjD,MAAM,CAAC,GAAG,OAAV,MAAM,GAAK,CAAC,CAAC,GAAG,OAAL,CAAC,EAAQ,IAAI,UAAM,GAAG,GAAE;SACpC;QACD,OAAO,MAAM,CAAC,QAAQ,EAAO,CAAC;IAChC,CAAC;IAED,gCAAO,GAAP,UAA0B,CAAI,EAAE,IAAc;QAC5C,IAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC5C,IAAM,OAAO,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC;gCAElB,CAAC;YACR,IAAM,MAAM,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YACpC,IAAM,KAAK,GAAG,MAAM,CAAC,KAAK,EAAE,CAAC;YAC7B,IAAI,CAAC,OAAO,CAAC,UAAA,EAAE,IAAI,OAAA,KAAK,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC,EAAE,CAAC,EAAvC,CAAuC,CAAC,CAAC;YAC5D,MAAM,CAAC,GAAG,OAAV,MAAM,GAAK,OAAO,CAAC,GAAG,OAAX,OAAO,EAAQ,KAAK,UAAM,MAAM,GAAE;QAC/C,CAAC;QALD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,IAAI,EAAE,CAAC,EAAE;oBAA3B,CAAC;SAKT;QAED,OAAO,MAAM,CAAC,QAAQ,EAAO,CAAC;IAChC,CAAC;IAGD,+BAAM,GAAN,UAAO,CAAW,EAAE,CAAW;QAC7B,IAAM,QAAQ,GAAG,WAAW,CAAC,eAAe,CACvB,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAgC,CAAC;QACzE,IAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAU,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAEtD,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;YAExC,IAAM,KAAK,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;YAC3B,IAAM,KAAK,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;YAC3B,IAAM,IAAI,GAAG,MAAM,CAAC,MAAM,CAAC;YAC3B,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;YACnB,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,CAAC,CAAC,IAAI,CAAC,CAAC;YACxB,OAAO,MAAM,CAAC,QAAQ,EAAE,CAAC;SAC1B;QAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE;YACpC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE;gBACnC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;aAC/B;YACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE;gBACnC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;aAC5C;SACF;QACD,OAAO,MAAM,CAAC,QAAQ,EAAE,CAAC;IAC3B,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAM,CAAC;IAC/C,CAAC;IAED,4BAAG,GAAH,UAAI,CAAS,EAAE,CAAS;QACtB,OAAO,IAAI,CAAC,mBAAmB,CACpB,CAAC,EAAE,CAAC,EAAE,KAAK,CAAC,UAAU,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,EACxC,UAAC,MAAM,EAAE,MAAM,IAAK,OAAA,MAAM,GAAG,MAAM,EAAf,CAAe,CAAW,CAAC;IAC5D,CAAC;IAED,iCAAQ,GAAR,UAAS,CAAS,EAAE,CAAS;QAC3B,OAAO,IAAI,CAAC,mBAAmB,CACpB,CAAC,EAAE,CAAC,EAAE,KAAK,CAAC,UAAU,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,EACxC,UAAC,MAAM,EAAE,MAAM,IAAK,OAAA,MAAM,GAAG,MAAM,EAAf,CAAe,CAAW,CAAC;IAC5D,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI,EAAE,CAAS;QACnC,OAAO,IAAI,CAAC,mBAAmB,CACpB,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAC,MAAM,EAAE,MAAM,IAAK,OAAA,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC,EAAxB,CAAwB,CACjE,CAAC;IACR,CAAC;IAED,+BAAM,GAAN,UAAO,CAAW,EAAE,CAAW,EAAE,UAAmB,EAAE,UAAmB;QAEvE,IAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACvD,IAAM,OAAO,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACrD,IAAM,QAAQ,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAEtD,IAAM,OAAO,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC7B,IAAM,OAAO,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAEvB,IAAA,uDAC8C,EAD7C,kBAAU,EAAE,kBAAU,CACwB;QAC/C,IAAA,uDAC8C,EAD7C,kBAAU,EAAE,kBAAU,CACwB;QAErD,IAAM,SAAS,GAAG,OAAO,GAAG,UAAU,CAAC;QACvC,IAAM,SAAS,GAAG,QAAQ,GAAG,UAAU,CAAC;QAExC,IAAM,MAAM,GAAG,IAAI,YAAY,CAAC,OAAO,GAAG,QAAQ,CAAC,CAAC;QACpD,IAAI,WAAW,GAAG,CAAC,CAAC;QAEpB,KAAK,IAAI,MAAM,GAAG,CAAC,EAAE,MAAM,GAAG,SAAS,EAAE,MAAM,IAAI,UAAU,EAAE;YAC7D,KAAK,IAAI,MAAM,GAAG,CAAC,EAAE,MAAM,GAAG,SAAS,EAAE,MAAM,IAAI,UAAU,EAAE;gBAC7D,IAAI,MAAM,GAAG,MAAM,CAAC;gBACpB,IAAI,MAAM,GAAG,MAAM,CAAC;gBACpB,IAAI,GAAG,GAAG,CAAC,CAAC;gBACZ,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;oBAClC,GAAG,IAAI,OAAO,CAAC,MAAM,CAAC,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC;oBACzC,MAAM,IAAI,UAAU,CAAC;oBACrB,MAAM,IAAI,UAAU,CAAC;iBACtB;gBACD,MAAM,CAAC,WAAW,EAAE,CAAC,GAAG,GAAG,CAAC;aAC7B;SACF;QACD,OAAO,GAAG,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC,OAAO,EAAE,QAAQ,CAAC,CAAC,CAAC;IACnD,CAAC;IAED,iCAAQ,GAAR,UAAS,CAAS,EAAE,CAAS;QAC3B,OAAO,IAAI,CAAC,mBAAmB,CACpB,CAAC,EAAE,CAAC,EAAE,KAAK,CAAC,UAAU,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,EACxC,UAAC,MAAM,EAAE,MAAM,IAAK,OAAA,MAAM,GAAG,MAAM,EAAf,CAAe,CAAW,CAAC;IAC5D,CAAC;IAED,+BAAM,GAAN,UAAO,CAAS,EAAE,CAAS;QACzB,IAAI,EAAoC,CAAC;QACzC,IAAI,WAA8B,CAAC;QACnC,IAAI,CAAC,CAAC,KAAK,KAAK,OAAO,IAAI,CAAC,CAAC,KAAK,KAAK,OAAO,EAAE;YAC9C,WAAW,GAAG,OAAO,CAAC;YACtB,EAAE,GAAG,UAAC,CAAS,EAAE,CAAS,IAAK,OAAA,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,EAAjB,CAAiB,CAAC;SAClD;aAAM;YACL,WAAW,GAAG,SAAS,CAAC;YACxB,EAAE,GAAG,UAAC,CAAS,EAAE,CAAS,IAAK,OAAA,CAAC,GAAG,CAAC,EAAL,CAAK,CAAC;SACtC;QACD,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,WAAW,EAAE,EAAE,CAAW,CAAC;IACnE,CAAC;IAED,4BAAG,GAAH,UAAI,CAAS,EAAE,IAAc;QAC3B,SAAS,CAAC,0BAA0B,CAAC,KAAK,EAAE,IAAI,EAAE,CAAC,CAAC,IAAI,CAAC,CAAC;QACpD,IAAA,uDACgD,EAD/C,gBAAQ,EAAE,mBAAW,CAC2B;QACvD,IAAM,WAAW,GAAG,KAAK,CAAC,UAAU,CAAC,CAAC,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QACvD,IAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,QAAQ,EAAE,WAAW,CAAC,CAAC;QAChD,IAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;QACnD,IAAM,IAAI,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC;QAE/B,IAAM,KAAK,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACpC,IAAM,MAAM,GAAG,CAAC,GAAG,UAAU,CAAC;YAC9B,IAAI,GAAG,GAAG,CAAC,CAAC;YACZ,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;gBACnC,GAAG,IAAI,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;aAC1B;YACD,IAAI,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;SACf;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,+BAAM,GAAN,UAAO,CAAS,EAAE,IAAY;QAC5B,IAAM,IAAI,GAAG,CAAC,IAAI,CAAC,CAAC;QACpB,SAAS,CAAC,0BAA0B,CAAC,QAAQ,EAAE,IAAI,EAAE,CAAC,CAAC,IAAI,CAAC,CAAC;QACvD,IAAA,uDACgD,EAD/C,gBAAQ,EAAE,mBAAW,CAC2B;QACvD,IAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;QAC5C,IAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;QACnD,IAAM,IAAI,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC;QAE/B,IAAM,KAAK,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACpC,IAAM,MAAM,GAAG,CAAC,GAAG,UAAU,CAAC;YAC9B,IAAI,GAAG,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC;YACxB,IAAI,QAAQ,GAAG,CAAC,CAAC;YACjB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;gBACnC,IAAM,KAAK,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBAChC,IAAI,KAAK,GAAG,GAAG,EAAE;oBACf,GAAG,GAAG,KAAK,CAAC;oBACZ,QAAQ,GAAG,CAAC,CAAC;iBACd;aACF;YACD,IAAI,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC;SACpB;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,+BAAM,GAAN,UAAO,CAAS,EAAE,IAAY;QAC5B,IAAM,IAAI,GAAG,CAAC,IAAI,CAAC,CAAC;QACpB,SAAS,CAAC,0BAA0B,CAAC,QAAQ,EAAE,IAAI,EAAE,CAAC,CAAC,IAAI,CAAC,CAAC;QACvD,IAAA,uDACgD,EAD/C,gBAAQ,EAAE,mBAAW,CAC2B;QACvD,IAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;QAC5C,IAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;QACnD,IAAM,IAAI,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC;QAE/B,IAAM,KAAK,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACpC,IAAM,MAAM,GAAG,CAAC,GAAG,UAAU,CAAC;YAC9B,IAAI,GAAG,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC;YACxB,IAAI,QAAQ,GAAG,CAAC,CAAC;YACjB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;gBACnC,IAAM,KAAK,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBAChC,IAAI,KAAK,GAAG,GAAG,EAAE;oBACf,GAAG,GAAG,KAAK,CAAC;oBACZ,QAAQ,GAAG,CAAC,CAAC;iBACd;aACF;YACD,IAAI,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC;SACpB;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,8BAAK,GAAL,UAAM,CAAS,EAAE,CAAS;QACxB,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,CAAC,IAAI,KAAK,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACjC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,iCAAQ,GAAR,UAAS,CAAS,EAAE,CAAS;QAC3B,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,CAAC,IAAI,KAAK,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACjC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,6BAAI,GAAJ,UAAK,CAAS,EAAE,CAAS;QACvB,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,CAAC,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,kCAAS,GAAT,UAAU,CAAS,EAAE,CAAS;QAC5B,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAChC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,gCAAO,GAAP,UAAQ,CAAS,EAAE,CAAS;QAC1B,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,CAAC,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,qCAAY,GAAZ,UAAa,CAAS,EAAE,CAAS;QAC/B,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAChC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,mCAAU,GAAV,UAA6B,CAAI;QAC/B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,UAAU,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAChD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,SAAS,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;SAClC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,EAAE,MAAM,CAAM,CAAC;IAChE,CAAC;IAED,mCAAU,GAAV,UAAW,CAAS,EAAE,CAAS;QAC7B,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,IAAI,IAAI,IAAI,CAAC;QACtB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,kCAAS,GAAT,UAAU,CAAS,EAAE,CAAS;QAC5B,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,EAAE,UAAC,IAAI,EAAE,IAAI;YACvD,OAAO,IAAI,IAAI,IAAI,CAAC;QACtB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,8BAAK,GAAL,UAAM,SAAiB,EAAE,CAAS,EAAE,CAAS,EAAE,KAAe;QAC5D,IAAM,MAAM,GAAG,SAAS,CAAC,QAAQ,EAAE,CAAC;QACpC,IAAM,OAAO,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC7B,IAAM,OAAO,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC7B,IAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACzC,IAAM,SAAS,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC;QACpC,IAAI,KAAK,GAAG,CAAC,CAAC;QACd,IAAM,MAAM,GAAG,SAAS,CAAC,IAAI,KAAK,CAAC,IAAI,SAAS,CAAC,IAAI,GAAG,CAAC,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC;YACvE,CAAC,CAAC,CAAC;YACH,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAEf,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,EAAE;gBAC/B,IAAI,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;oBACnB,SAAS,CAAC,KAAK,EAAE,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;iBACjC;qBAAM;oBACL,SAAS,CAAC,KAAK,EAAE,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;iBACjC;aACF;SACF;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,mCAAU,GAAV,UAA6B,CAAI,EAAE,CAAS;QAC1C,OAAO,IAAI,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAkB,CAAC;IAC5C,CAAC;IAED,oCAAW,GAAX,UAAY,CAAS,EAAE,CAAS;QAC9B,OAAO,IAAI,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC;IACjC,CAAC;IAEO,6BAAI,GAAZ,UAA+B,CAAI,EAAE,CAAS;QAE5C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,gBAAgB,GAA0C,EAAE,CAAC;QACnE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACtC,gBAAgB,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC,EAAE,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;SACrD;QACD,gBAAgB,CAAC,IAAI,CAAC,UAAC,CAAC,EAAE,CAAC;YACzB,OAAO,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC;QAC3B,CAAC,CAAC,CAAC;QAEH,IAAM,UAAU,GAAG,IAAI,CAAC,sBAAsB,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;QAC3D,IAAM,WAAW,GAAG,IAAI,UAAU,CAAC,CAAC,CAAC,CAAC;QACtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;YAC1B,UAAU,CAAC,CAAC,CAAC,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;YAC1C,WAAW,CAAC,CAAC,CAAC,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;SAC5C;QACD,OAAO;YACL,MAAM,EAAE,GAAG,CAAC,QAAQ,CAAC,UAAU,EAAE,CAAC,CAAC,KAAK,CAAC;YACzC,OAAO,EAAE,GAAG,CAAC,QAAQ,CAAC,WAAW,EAAE,OAAO,CAAC;SAC5C,CAAC;IACJ,CAAC;IAED,4BAAG,GAAH,UAAI,CAAS,EAAE,IAAc;QAC3B,SAAS,CAAC,0BAA0B,CAAC,KAAK,EAAE,IAAI,EAAE,CAAC,CAAC,IAAI,CAAC,CAAC;QACpD,IAAA,uDACgD,EAD/C,gBAAQ,EAAE,mBAAW,CAC2B;QACvD,IAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC5C,IAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;QACnD,IAAM,IAAI,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC;QAE/B,IAAM,KAAK,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACpC,IAAM,MAAM,GAAG,CAAC,GAAG,UAAU,CAAC;YAC9B,IAAI,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;YACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;gBACnC,IAAM,KAAK,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBAChC,IAAI,KAAK,GAAG,GAAG,EAAE;oBACf,GAAG,GAAG,KAAK,CAAC;iBACb;aACF;YACD,IAAI,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;SACf;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,gCAAO,GAAP,UAAQ,CAAS,EAAE,CAAS;QAC1B,OAAO,IAAI,CAAC,mBAAmB,CAC3B,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAC,IAAI,EAAE,IAAI,IAAK,OAAA,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,CAAC,EAApB,CAAoB,CAAC,CAAC;IAC3D,CAAC;IAED,4BAAG,GAAH,UAAI,CAAS,EAAE,CAAS;QACtB,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAC,IAAI,EAAE,IAAI;YACxD,IAAM,GAAG,GAAG,IAAI,GAAG,IAAI,CAAC;YACxB,IAAI,CAAC,IAAI,GAAG,CAAC,IAAI,IAAI,GAAG,CAAC,CAAC,IAAI,CAAC,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,EAAE;gBACtD,OAAO,GAAG,CAAC;aACZ;iBAAM;gBACL,OAAO,CAAC,GAAG,GAAG,IAAI,CAAC,GAAG,IAAI,CAAC;aAC5B;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED,4BAAG,GAAH,UAAI,CAAS,EAAE,IAAc;QAC3B,SAAS,CAAC,0BAA0B,CAAC,KAAK,EAAE,IAAI,EAAE,CAAC,CAAC,IAAI,CAAC,CAAC;QACpD,IAAA,uDACgD,EAD/C,gBAAQ,EAAE,mBAAW,CAC2B;QACvD,IAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC5C,IAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;QACnD,IAAM,IAAI,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC;QAE/B,IAAM,KAAK,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACpC,IAAM,MAAM,GAAG,CAAC,GAAG,UAAU,CAAC;YAC9B,IAAI,GAAG,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC;YACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;gBACnC,IAAM,KAAK,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBAChC,IAAI,KAAK,GAAG,GAAG,EAAE;oBACf,GAAG,GAAG,KAAK,CAAC;iBACb;aACF;YACD,IAAI,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;SACf;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,gCAAO,GAAP,UAAQ,CAAS,EAAE,CAAS;QAC1B,OAAO,IAAI,CAAC,mBAAmB,CAC3B,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAC,IAAI,EAAE,IAAI,IAAK,OAAA,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,CAAC,EAApB,CAAoB,CAAC,CAAC;IAC3D,CAAC;IAED,0CAAiB,GAAjB,UAAkB,CAAS,EAAE,CAAS;QACpC,OAAO,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAC,IAAI,EAAE,IAAI;YACxD,IAAM,IAAI,GAAG,IAAI,GAAG,IAAI,CAAC;YACzB,OAAO,IAAI,GAAG,IAAI,CAAC;QACrB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACrC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACtC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;gBACjB,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;aACnB;iBAAM,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;gBACxB,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;aAClB;iBAAM;gBACL,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;aAClB;SACF;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAEtC,IAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YACnC,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,GAAG,GAAG,EAAE;gBAC1B,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;aACtC;iBAAM,IAAI,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,GAAG,GAAG,EAAE;gBACjC,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;aACrC;iBAAM;gBACL,IAAI,IAAI,GAAG,GAAG,KAAK,GAAG,EAAE;oBACtB,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC;iBACrB;qBAAM;oBACL,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,GAAG,GAAG,CAAC;iBAC3B;aACF;SACF;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACpC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACtC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACxB,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;SAChC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACxB,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;SAClC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACxB,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACjC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACxB,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACrC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,+BAAM,GAAN,UAAyB,CAAI;QAC3B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACxB,SAAS,CAAC,CAAC,CAAC,GAAG,KAAK,GAAG,KAAK,CAAC;SAC9B;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,mCAAU,GAAV,UAA6B,CAAI;QAC/B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QAClD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;SAC9B;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,SAAS,EAAC,CAAM,CAAC;IACxD,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QACxC,IAAM,OAAO,GAAG,GAAG,CAAC,QAAQ,EAAE,CAAC;QAC/B,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACrC;QACD,OAAO,GAAQ,CAAC;IAClB,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,IAAI,CAAC,EAAE;gBACV,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;aACrB;iBAAM;gBACL,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;aACrC;SACF;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,+BAAM,GAAN,UAAyB,EAAK,EAAE,CAAI;QAClC,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,EAAE,CAAC;QAC/B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,IAAI,CAAC,EAAE;gBACV,YAAY,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;aAC/B;iBAAM;gBACL,YAAY,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;aACzC;SACF;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QAGzB,IAAM,UAAU,GAAG,SAAS,CAAC,eAAe,CAAC;QAC7C,IAAM,KAAK,GAAG,SAAS,CAAC,UAAU,CAAC;QAEnC,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,IAAI,CAAC,EAAE;gBACV,YAAY,CAAC,CAAC,CAAC,GAAG,KAAK,GAAG,CAAC,CAAC;aAC7B;iBAAM;gBACL,YAAY,CAAC,CAAC,CAAC,GAAG,UAAU,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;aAClD;SACF;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI,EAAE,GAAW,EAAE,GAAW;QACnD,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;SAC3D;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACvC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,YAAY,GAAG,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC5C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;SAC7B;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,EAAE,OAAO,CAAC,CAAC;IAC/D,CAAC;IAED,gCAAO,GAAP,UAA0B,CAAI;QAC5B,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;SAClD;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,iCAAQ,GAAR,UAA2B,CAAI;QAM7B,IAAM,OAAO,GAAG,qBAAqB,CAAC;QACtC,IAAM,SAAS,GAAG,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,GAAG,CAAC;QAE1C,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAE5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAGtC,IAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,SAAS,CAAC;YAIxC,IAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC;YAEvC,IAAM,IAAI,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YACjC,IAAI,MAAM,SAAA,CAAC;YAEX,IAAI,QAAQ,EAAE;gBACZ,MAAM,GAAG,IAAI,CAAC;aACf;iBAAM,IAAI,QAAQ,EAAE;gBACnB,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;aACpB;iBAAM;gBACL,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,GAAG,IAAI,CAAC,CAAC;aAC/B;YACD,YAAY,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;SAC1B;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACvC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACvC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACvC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACxC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACxC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACxC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI,EAAE,CAAI;QAChC,OAAO,IAAI,CAAC,mBAAmB,CACpB,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,UAAC,MAAM,EAAE,MAAM,IAAK,OAAA,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,CAAC,EAA1B,CAA0B,CACnE,CAAC;IACR,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACxC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACxC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI;QACzB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACxC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACzC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACzC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,8BAAK,GAAL,UAAwB,CAAI;QAC1B,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SACzC;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,4BAAG,GAAH,UAAsB,CAAI;QACxB,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,CAAC,GAAG,QAAQ,CAAC,KAAK,CAAC;QACzB,IAAM,EAAE,GAAG,QAAQ,CAAC,MAAM,CAAC;QAC3B,IAAM,EAAE,GAAG,QAAQ,CAAC,MAAM,CAAC;QAC3B,IAAM,EAAE,GAAG,QAAQ,CAAC,MAAM,CAAC;QAC3B,IAAM,EAAE,GAAG,QAAQ,CAAC,MAAM,CAAC;QAC3B,IAAM,EAAE,GAAG,QAAQ,CAAC,MAAM,CAAC;QAC3B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACpB,IAAM,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;YAC9B,YAAY,CAAC,CAAC,CAAC;kBACT,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAC,CAAC,GAAG,EAAE,CAAC,GAAC,CAAC,CAAC,GAAG,EAAE,CAAC,GAAC,CAAC,GAAG,EAAE,CAAC,GAAC,CAAC,GAAG,EAAE,CAAC,GAAC,CAAC,GAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAC,CAAC,CAAC,CAAC;SACvE;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI,EAAE,KAAS;QAAT,sBAAA,EAAA,SAAS;QACpC,IAAM,YAAY,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACtC,IAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACxB,IAAI,KAAK,CAAC,KAAK,CAAC,EAAE;gBAChB,YAAY,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;aACvB;iBAAM;gBACL,YAAY,CAAC,CAAC,CAAC,GAAG,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;aACzC;SACF;QACD,OAAO,eAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,YAAY,EAAC,CAAM,CAAC;IAC3D,CAAC;IAED,+BAAM,GAAN,UAAO,CAAW,EAAE,MAAgB,EAAE,QAAoB;QACxD,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,cAAc,GAAG,QAAQ,CAAC,cAAc,CAAC;QAC/C,IAAM,aAAa,GAAG,QAAQ,CAAC,aAAa,CAAC;QAC7C,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QACtC,IAAM,MAAM,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QACpC,IAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAU,QAAQ,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAE1D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,CAAC,EAAE;YAC3C,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,WAAW,EAAE,EAAE,EAAE,EAAE;gBAChD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,EAAE,EAAE;oBAC9C,IAAM,QAAQ,GAAG,EAAE,GAAG,QAAQ,CAAC,YAAY,GAAG,OAAO,CAAC;oBACtD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,QAAQ,EAAE,EAAE,EAAE,EAAE;wBAC7C,IAAM,QAAQ,GAAG,EAAE,GAAG,QAAQ,CAAC,WAAW,GAAG,MAAM,CAAC;wBAEpD,IAAI,OAAO,GAAG,CAAC,CAAC;wBAChB,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,YAAY,EAAE,EAAE,EAAE,EAAE;4BACxC,IAAM,EAAE,GAAG,QAAQ,GAAG,EAAE,GAAG,cAAc,CAAC;4BAE1C,IAAI,EAAE,GAAG,CAAC,IAAI,EAAE,IAAI,QAAQ,CAAC,QAAQ,EAAE;gCACrC,SAAS;6BACV;4BAED,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,WAAW,EAAE,EAAE,EAAE,EAAE;gCACvC,IAAM,EAAE,GAAG,QAAQ,GAAG,EAAE,GAAG,aAAa,CAAC;gCAEzC,IAAI,EAAE,GAAG,CAAC,IAAI,EAAE,IAAI,QAAQ,CAAC,OAAO,EAAE;oCACpC,SAAS;iCACV;gCAED,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,UAAU,EAAE,EAAE,EAAE,EAAE;oCAC/C,IAAM,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC;oCACnC,IAAM,MAAM,GAAG,MAAM,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC;oCAC1C,OAAO,IAAI,KAAK,GAAG,MAAM,CAAC;iCAC3B;6BACF;yBACF;wBACD,CAAC,CAAC,GAAG,CAAC,OAAO,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC;qBAC/B;iBACF;aACF;SACF;QACD,OAAO,CAAC,CAAC,QAAQ,EAAE,CAAC;IACtB,CAAC;IAED,uCAAc,GAAd,UAAe,EAAY,EAAE,MAAgB,EAAE,QAAoB;QAEjE,IAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAU,QAAQ,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC;QAC5D,IAAM,QAAQ,GAAG,EAAE,CAAC,MAAM,CAAC;QACrB,IAAA,eAA+B,EAA9B,YAAI,EAAE,YAAI,EAAE,YAAI,CAAe;QACtC,IAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,EAAE,CAAC;QACzB,IAAA,eAA+B,EAA9B,YAAI,EAAE,YAAI,EAAE,YAAI,CAAe;QACtC,IAAM,SAAS,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC;QAC9B,IAAA,mBAAsC,EAArC,aAAK,EAAE,aAAK,EAAE,aAAK,CAAmB;QACtC,IAAA,8BAAS,EAAE,oCAAY,EAAE,kCAAW,EACpC,gCAAU,EAAE,4BAAQ,EAAE,0BAAO,EAC7B,kCAAW,EAAE,8BAAS,EAAE,4BAAQ,EAChC,oCAAY,EAAE,kCAAW,CAAa;QAC7C,IAAM,MAAM,GAAG,YAAY,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QACvD,IAAM,OAAO,GAAG,WAAW,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QAExD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;YAClC,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,UAAU,EAAE,EAAE,EAAE,EAAE;gBACtC,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,EAAE,EAAE,EAAE,EAAE;oBACpC,IAAM,QAAQ,GAAG,EAAE,GAAG,OAAO,CAAC;oBAC9B,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,YAAY,CAAC,CAAC,CAAC;oBAC9D,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAClB,SAAS,EAAE,CAAC,YAAY,GAAG,QAAQ,CAAC,GAAG,YAAY,CAAC,CAAC;oBAEzD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,OAAO,EAAE,EAAE,EAAE,EAAE;wBACnC,IAAM,QAAQ,GAAG,EAAE,GAAG,MAAM,CAAC;wBAC7B,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,WAAW,CAAC,CAAC,CAAC;wBAC7D,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAClB,QAAQ,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC,GAAG,WAAW,CAAC,CAAC;wBAEtD,IAAI,OAAO,GAAG,CAAC,CAAC;wBAChB,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;4BACrC,IAAM,EAAE,GAAG,EAAE,GAAG,YAAY,GAAG,QAAQ,CAAC;4BAExC,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;gCACrC,IAAM,EAAE,GAAG,EAAE,GAAG,WAAW,GAAG,QAAQ,CAAC;gCACvC,IAAM,QAAQ,GAAG,IAAI,GAAG,CAAC,GAAG,IAAI,GAAG,EAAE,GAAG,IAAI,GAAG,EAAE,CAAC;gCAClD,IAAM,SAAS,GAAG,KAAK,GAAG,CAAC,YAAY,GAAG,CAAC,GAAG,EAAE,CAAC;oCAC/B,KAAK,GAAG,CAAC,WAAW,GAAG,CAAC,GAAG,EAAE,CAAC;oCAC9B,KAAK,GAAG,EAAE,CAAC;gCAE7B,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,WAAW,EAAE,EAAE,EAAE,EAAE;oCACvC,IAAM,KAAK,GAAG,QAAQ,CAAC,QAAQ,GAAG,EAAE,CAAC,CAAC;oCACtC,IAAM,MAAM,GAAG,SAAS,CAAC,SAAS,GAAG,EAAE,CAAC,CAAC;oCACzC,OAAO,IAAI,KAAK,GAAG,MAAM,CAAC;iCAC3B;6BACF;yBACF;wBACD,QAAQ,CAAC,IAAI,GAAG,CAAC,GAAG,IAAI,GAAG,EAAE,GAAG,IAAI,GAAG,EAAE,GAAG,EAAE,CAAC,GAAG,OAAO,CAAC;qBAC3D;iBACF;aACF;SACF;QACD,OAAO,EAAE,CAAC,QAAQ,EAAE,CAAC;IACvB,CAAC;IAED,wCAAe,GAAf,UAAgB,CAAW,EAAE,EAAY,EAAE,QAAoB;QAC7D,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAU,QAAQ,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC;QAEhE,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QACtC,IAAM,MAAM,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QAEpC,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,YAAY,EAAE,EAAE,EAAE,EAAE;YACxC,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC,MAAM,GAAG,EAAE,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC;YACnE,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAClB,QAAQ,CAAC,SAAS,EAAE,CAAC,QAAQ,CAAC,QAAQ,GAAG,MAAM,GAAG,EAAE,CAAC,GAAG,YAAY,CAAC,CAAC;YAE1E,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,WAAW,EAAE,EAAE,EAAE,EAAE;gBACvC,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC,OAAO,GAAG,EAAE,CAAC,GAAG,WAAW,CAAC,CAAC,CAAC;gBACnE,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAClB,QAAQ,CAAC,QAAQ,EAAE,CAAC,QAAQ,CAAC,OAAO,GAAG,OAAO,GAAG,EAAE,CAAC,GAAG,WAAW,CAAC,CAAC;gBAExE,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,UAAU,EAAE,EAAE,EAAE,EAAE;oBAC/C,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,WAAW,EAAE,EAAE,EAAE,EAAE;wBAEhD,IAAI,OAAO,GAAG,CAAC,CAAC;wBAChB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,CAAC,EAAE;4BAC3C,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;gCACrC,IAAM,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,YAAY,GAAG,MAAM,CAAC;gCAC3C,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;oCACrC,IAAM,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,WAAW,GAAG,OAAO,CAAC;oCAC3C,OAAO,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC;iCACzD;6BACF;yBACF;wBACD,EAAE,CAAC,GAAG,CAAC,OAAO,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC;qBACjC;iBACF;aACF;SACF;QACD,OAAO,EAAE,CAAC,QAAQ,EAAE,CAAC;IACvB,CAAC;IAED,wCAAe,GAAf,UAAgB,CAAW,EAAE,MAAgB,EAAE,QAAoB;QAEjE,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,cAAc,GAAG,QAAQ,CAAC,cAAc,CAAC;QAC/C,IAAM,aAAa,GAAG,QAAQ,CAAC,aAAa,CAAC;QAC7C,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QACtC,IAAM,MAAM,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QACpC,IAAM,KAAK,GAAG,QAAQ,CAAC,WAAW,GAAG,QAAQ,CAAC,UAAU,CAAC;QACzD,IAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAU,QAAQ,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAE1D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,CAAC,EAAE;YAC3C,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,UAAU,EAAE,EAAE,EAAE,EAAE;gBAC/C,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,EAAE,EAAE;oBAC9C,IAAM,QAAQ,GAAG,EAAE,GAAG,QAAQ,CAAC,YAAY,GAAG,OAAO,CAAC;oBACtD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,QAAQ,EAAE,EAAE,EAAE,EAAE;wBAC7C,IAAM,QAAQ,GAAG,EAAE,GAAG,QAAQ,CAAC,WAAW,GAAG,MAAM,CAAC;wBACpD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,EAAE,CAAC,EAAE;4BAC9B,IAAI,OAAO,GAAG,CAAC,CAAC;4BAChB,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,YAAY,EAAE,EAAE,EAAE,EAAE;gCACxC,IAAM,EAAE,GAAG,QAAQ,GAAG,EAAE,GAAG,cAAc,CAAC;gCAE1C,IAAI,EAAE,GAAG,CAAC,IAAI,EAAE,IAAI,QAAQ,CAAC,QAAQ,EAAE;oCACrC,SAAS;iCACV;gCAED,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,WAAW,EAAE,EAAE,EAAE,EAAE;oCACvC,IAAM,EAAE,GAAG,QAAQ,GAAG,EAAE,GAAG,aAAa,CAAC;oCAEzC,IAAI,EAAE,GAAG,CAAC,IAAI,EAAE,IAAI,QAAQ,CAAC,OAAO,EAAE;wCACpC,SAAS;qCACV;oCAED,IAAM,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC;oCACnC,IAAM,MAAM,GAAG,MAAM,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;oCACzC,OAAO,IAAI,KAAK,GAAG,MAAM,CAAC;iCAC3B;6BACF;4BACD,CAAC,CAAC,GAAG,CAAC,OAAO,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,GAAG,KAAK,GAAG,CAAC,CAAC,CAAC;yBAC3C;qBACF;iBACF;aACF;SACF;QAED,OAAO,CAAC,CAAC,QAAQ,EAAE,CAAC;IACtB,CAAC;IAED,6BAAI,GAAJ,UAAuB,CAAI,EAAE,IAAc;QACzC,IAAM,QAAQ,GAAa,IAAI,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC7C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACxC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;SACpC;QACD,IAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC7C,IAAM,IAAI,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC;QACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YAC7C,IAAM,MAAM,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YAEpC,IAAM,WAAW,GAAa,IAAI,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;YAChD,KAAK,IAAI,GAAC,GAAG,CAAC,EAAE,GAAC,GAAG,WAAW,CAAC,MAAM,EAAE,GAAC,EAAE,EAAE;gBAC3C,WAAW,CAAC,GAAC,CAAC,GAAG,MAAM,CAAC,GAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,GAAC,CAAC,CAAC;aACzC;YAED,IAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,CAAC;YAEnD,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;SAC/C;QACD,OAAO,MAAM,CAAC,QAAQ,EAAO,CAAC;IAChC,CAAC;IAED,4BAAG,GAAH,UACI,CAAI,EAAE,QAAiC,EAAE,aAAqB;QAChE,IAAM,QAAQ,GAAG,QAAQ,CAAC,GAAG,CACzB,UAAC,CAAC,EAAE,CAAC,IAAK,OAAA,CAAC,CAAC,CAAC,CAAC,GAAmB,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAxC,CAAwC,CAAgB,CAAC;QACvE,IAAM,KAAK,GAAG,QAAQ,CAAC,GAAG,CAAC,UAAA,CAAC,IAAI,OAAA,CAAC,CAAC,CAAC,CAAC,EAAJ,CAAI,CAAC,CAAC;QACtC,IAAM,OAAO,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC;QAC3B,IAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC7C,IAAI,aAAa,KAAK,CAAC,EAAE;YACvB,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;SACnC;QAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAC,EAAE,EAAE;YAC/B,IAAM,MAAM,GAAG,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YACrC,IAAM,SAAS,GAAG,MAAM,CAAC,GAAG,CAAC,UAAC,CAAC,EAAE,CAAC,IAAK,OAAA,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAZ,CAAY,CAAC,CAAC;YACrD,MAAM,CAAC,GAAG,OAAV,MAAM,GAAK,CAAC,CAAC,GAAG,OAAL,CAAC,EAAQ,MAAM,UAAM,SAAS,GAAE;SAC5C;QACD,OAAO,MAAM,CAAC,QAAQ,EAAO,CAAC;IAChC,CAAC;IAED,kCAAS,GAAT,UAA4B,CAAI,EAAE,IAAc;QAC9C,IAAM,QAAQ,GAAa,IAAI,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAC7C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACxC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;SAChC;QACD,IAAM,MAAM,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC5B,IAAM,MAAM,GAAG,YAAM,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAEzC,IAAM,IAAI,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC;QACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE;YAC/B,IAAM,GAAG,GAAG,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YAG/B,IAAM,MAAM,GAAa,IAAI,KAAK,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC/C,KAAK,IAAI,GAAC,GAAG,CAAC,EAAE,GAAC,GAAG,MAAM,CAAC,MAAM,EAAE,GAAC,EAAE,EAAE;gBACtC,MAAM,CAAC,GAAC,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,GAAC,CAAC,CAAC,CAAC;aAC1B;YAED,IAAM,QAAQ,GAAG,MAAM,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;YAC3C,MAAM,CAAC,MAAM,CAAC,QAAQ,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;SACrC;QACD,OAAO,MAAM,CAAC,QAAQ,EAAO,CAAC;IAChC,CAAC;IAED,+BAAM,GAAN,UAAyB,CAAI,EAAE,OAAiB,EAAE,IAAY;QAC5D,IAAM,QAAQ,GAAa,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QAC3C,IAAM,aAAa,GAAG,OAAO,CAAC,QAAQ,EAAE,CAAC;QACzC,QAAQ,CAAC,IAAI,CAAC,GAAG,aAAa,CAAC,MAAM,CAAC;QACtC,IAAM,MAAM,GAAG,YAAM,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QACzC,IAAM,IAAI,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC;QAExB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE;YACpC,IAAM,MAAM,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YAEpC,IAAM,WAAW,GAAa,MAAM,CAAC,KAAK,EAAE,CAAC;YAC7C,WAAW,CAAC,IAAI,CAAC,GAAG,aAAa,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;YAEhD,IAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,CAAC;YACnD,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;SAC/C;QACD,OAAO,MAAM,CAAC,QAAQ,EAAO,CAAC;IAChC,CAAC;IAEO,6BAAI,GAAZ,UAAa,CAAW,EAAE,QAAoB,EAAE,QAAqB;QAEnE,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAU,QAAQ,CAAC,QAAQ,EAAE,SAAS,CAAC,CAAC;QAC5D,IAAM,MAAM,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QACpC,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QACtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,CAAC,EAAE;YAC3C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,UAAU,EAAE,EAAE,CAAC,EAAE;gBAC5C,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,EAAE,EAAE;oBAC9C,IAAM,QAAQ,GAAG,EAAE,GAAG,YAAY,GAAG,MAAM,CAAC;oBAC5C,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;oBACpC,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,QAAQ,EAAE,YAAY,GAAG,QAAQ,CAAC,CAAC;oBACnE,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,QAAQ,EAAE,EAAE,EAAE,EAAE;wBAC7C,IAAM,QAAQ,GAAG,EAAE,GAAG,WAAW,GAAG,OAAO,CAAC;wBAC5C,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;wBACpC,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,OAAO,EAAE,WAAW,GAAG,QAAQ,CAAC,CAAC;wBAEjE,IAAI,WAAW,GACX,CAAC,QAAQ,KAAK,KAAK,CAAC,CAAC,CAAC,MAAM,CAAC,iBAAiB,CAAC,CAAC;4BAC1B,MAAM,CAAC,iBAAiB,CAAC,CAAC;wBACpD,IAAI,QAAQ,GAAG,CAAC,CAAC;wBACjB,IAAI,KAAK,GAAG,CAAC,CAAC;wBACd,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;4BACrC,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;gCACrC,IAAM,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;gCAClC,IAAI,CAAC,QAAQ,KAAK,KAAK,IAAI,KAAK,GAAG,WAAW,CAAC,EAAE;oCAC/C,WAAW,GAAG,KAAK,CAAC;iCACrB;qCAAM,IAAI,QAAQ,KAAK,KAAK,EAAE;oCAC7B,QAAQ,IAAI,KAAK,CAAC;oCAClB,KAAK,EAAE,CAAC;iCACT;6BACF;4BACD,IAAI,KAAK,CAAC,WAAW,CAAC,EAAE;gCACtB,MAAM;6BACP;yBACF;wBACD,CAAC,CAAC,GAAG,CACD,QAAQ,KAAK,KAAK,CAAC,CAAC,CAAC,QAAQ,GAAG,KAAK,CAAC,CAAC,CAAC,WAAW,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,EAC9D,CAAC,CAAC,CAAC;qBACR;iBACF;aACF;SACF;QACD,OAAO,CAAC,CAAC,QAAQ,EAAE,CAAC;IACtB,CAAC;IAED,gCAAO,GAAP,UAAQ,CAAW,EAAE,QAAoB;QACvC,OAAO,IAAI,CAAC,IAAI,CAAC,CAAC,EAAE,QAAQ,EAAE,KAAK,CAAC,CAAC;IACvC,CAAC;IAEO,yCAAgB,GAAxB,UAAyB,CAAW,EAAE,QAAoB;QACxD,IAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAU,QAAQ,CAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;QACrE,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,MAAM,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QACpC,IAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QAEtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,CAAC,EAAE;YAC3C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,UAAU,EAAE,EAAE,CAAC,EAAE;gBAC5C,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,EAAE,EAAE;oBAC9C,IAAM,QAAQ,GAAG,EAAE,GAAG,YAAY,GAAG,MAAM,CAAC;oBAC5C,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;oBACpC,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,QAAQ,EAAE,YAAY,GAAG,QAAQ,CAAC,CAAC;oBACnE,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,QAAQ,CAAC,QAAQ,EAAE,EAAE,EAAE,EAAE;wBAC7C,IAAM,QAAQ,GAAG,EAAE,GAAG,WAAW,GAAG,OAAO,CAAC;wBAC5C,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;wBACpC,IAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,OAAO,EAAE,WAAW,GAAG,QAAQ,CAAC,CAAC;wBACjE,IAAI,QAAQ,GAAG,MAAM,CAAC,iBAAiB,CAAC;wBACxC,IAAI,WAAW,GAAG,CAAC,CAAC,CAAC;wBACrB,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;4BACrC,IAAM,EAAE,GAAG,EAAE,GAAG,QAAQ,CAAC;4BACzB,KAAK,IAAI,EAAE,GAAG,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE,EAAE,EAAE,EAAE;gCACrC,IAAM,EAAE,GAAG,EAAE,GAAG,QAAQ,CAAC;gCACzB,IAAM,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;gCAClC,IAAI,KAAK,GAAG,QAAQ,EAAE;oCACpB,QAAQ,GAAG,KAAK,CAAC;oCACjB,WAAW,GAAG,EAAE,GAAG,WAAW,GAAG,EAAE,CAAC;iCACrC;6BACF;yBACF;wBACD,YAAY,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;qBAC7C;iBACF;aACF;SACF;QACD,OAAO,YAAY,CAAC,QAAQ,EAAE,CAAC;IACjC,CAAC;IAED,wCAAe,GAAf,UAAgB,EAAY,EAAE,CAAW,EAAE,CAAW,EAAE,QAAoB;QAE1E,IAAM,YAAY,GAAG,IAAI,CAAC,gBAAgB,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC;QACxD,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,OAAO,GAAG,WAAW,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QACxD,IAAM,MAAM,GAAG,YAAY,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QACvD,IAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAU,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;QAEnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,CAAC,EAAE;YAC3C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,UAAU,EAAE,EAAE,CAAC,EAAE;gBAC5C,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,QAAQ,CAAC,QAAQ,EAAE,EAAE,GAAG,EAAE;oBAChD,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,QAAQ,CAAC,OAAO,EAAE,EAAE,GAAG,EAAE;wBAE/C,IAAM,SAAS,GAAG,GAAG,GAAG,MAAM,CAAC;wBAC/B,IAAM,SAAS,GAAG,GAAG,GAAG,OAAO,CAAC;wBAChC,IAAI,OAAO,GAAG,CAAC,CAAC;wBAChB,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,YAAY,EAAE,EAAE,EAAE,EAAE;4BACxC,IAAM,GAAG,GAAG,CAAC,SAAS,GAAG,EAAE,CAAC,GAAG,YAAY,CAAC;4BAC5C,IAAI,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,QAAQ,CAAC,SAAS;gCACpC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,KAAK,GAAG,EAAE;gCAC3B,SAAS;6BACV;4BACD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,WAAW,EAAE,EAAE,EAAE,EAAE;gCACvC,IAAM,GAAG,GAAG,CAAC,SAAS,GAAG,EAAE,CAAC,GAAG,WAAW,CAAC;gCAC3C,IAAI,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,QAAQ,CAAC,QAAQ;oCACnC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,KAAK,GAAG,EAAE;oCAC3B,SAAS;iCACV;gCACD,IAAM,MAAM,GAAG,YAAY,GAAG,WAAW,GAAG,CAAC;oCACzC,YAAY,CAAC,GAAG,CAAC,CAAC,EAAE,GAAG,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC;gCACrC,IAAM,MAAM,GAAG,EAAE,GAAG,WAAW,GAAG,EAAE,CAAC;gCAErC,IAAM,IAAI,GAAG,MAAM,KAAK,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gCACvC,IAAI,IAAI,KAAK,CAAC,EAAE;oCACd,SAAS;iCACV;gCAED,IAAM,KAAK,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,EAAE,GAAG,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC;gCACrC,OAAO,IAAI,KAAK,GAAG,IAAI,CAAC;6BACzB;yBACF;wBACD,EAAE,CAAC,GAAG,CAAC,OAAO,EAAE,CAAC,EAAE,GAAG,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC;qBACjC;iBACF;aACF;SACF;QACD,OAAO,EAAE,CAAC,QAAQ,EAAE,CAAC;IACvB,CAAC;IAED,wCAAe,GAAf,UAAgB,EAAY,EAAE,CAAW,EAAE,QAAoB;QAC7D,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC;QAC3C,IAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAC;QACzC,IAAM,OAAO,GAAG,WAAW,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;QACxD,IAAM,MAAM,GAAG,YAAY,GAAG,CAAC,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;QACvD,IAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAU,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;QAEnD,IAAM,aAAa,GAAG,CAAC,GAAG,CAAC,YAAY,GAAG,WAAW,CAAC,CAAC;QAEvD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,SAAS,EAAE,EAAE,CAAC,EAAE;YAC3C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,UAAU,EAAE,EAAE,CAAC,EAAE;gBAC5C,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,QAAQ,CAAC,QAAQ,EAAE,EAAE,GAAG,EAAE;oBAChD,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,QAAQ,CAAC,OAAO,EAAE,EAAE,GAAG,EAAE;wBAE/C,IAAM,SAAS,GAAG,GAAG,GAAG,MAAM,CAAC;wBAC/B,IAAM,SAAS,GAAG,GAAG,GAAG,OAAO,CAAC;wBAChC,IAAI,OAAO,GAAG,CAAC,CAAC;wBAChB,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,YAAY,EAAE,EAAE,EAAE,EAAE;4BACxC,IAAM,GAAG,GAAG,CAAC,SAAS,GAAG,EAAE,CAAC,GAAG,YAAY,CAAC;4BAC5C,IAAI,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,QAAQ,CAAC,SAAS;gCACpC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,KAAK,GAAG,EAAE;gCAC3B,SAAS;6BACV;4BACD,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,WAAW,EAAE,EAAE,EAAE,EAAE;gCACvC,IAAM,GAAG,GAAG,CAAC,SAAS,GAAG,EAAE,CAAC,GAAG,WAAW,CAAC;gCAC3C,IAAI,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,QAAQ,CAAC,QAAQ;oCACnC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,KAAK,GAAG,EAAE;oCAC3B,SAAS;iCACV;gCAED,IAAM,KAAK,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,EAAE,GAAG,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC;gCACrC,OAAO,IAAI,KAAK,CAAC;6BAClB;yBACF;wBACD,EAAE,CAAC,GAAG,CAAC,OAAO,GAAG,aAAa,EAAE,CAAC,EAAE,GAAG,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC;qBACjD;iBACF;aACF;SACF;QACD,OAAO,EAAE,CAAC,QAAQ,EAAE,CAAC;IACvB,CAAC;IAED,6BAAI,GAAJ,UAAmC,CAAI,EAAE,KAAe;QACtD,OAAO,YAAY,CAAC,UAAU,CAAC,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;IACjD,CAAC;IAED,gCAAO,GAAP,UACI,CAAI,EAAE,KAAwB;QAChC,OAAO,YAAY,CAAC,aAAa,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;IAC9C,CAAC;IAED,gCAAO,GAAP,UAAQ,CAAW,EAAE,QAAoB;QACvC,OAAO,IAAI,CAAC,IAAI,CAAC,CAAC,EAAE,QAAQ,EAAE,KAAK,CAAC,CAAC,OAAO,EAAE,CAAC;IACjD,CAAC;IAED,uCAAc,GAAd,UACI,CAAW,EAAE,SAAiB,EAAE,QAAgB,EAChD,YAAqB;QACjB,IAAA,YAAmD,EAAlD,aAAK,EAAE,iBAAS,EAAE,gBAAQ,EAAE,mBAAW,CAAY;QAC1D,IAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAU,CAAC,KAAK,EAAE,SAAS,EAAE,QAAQ,EAAE,WAAW,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAE5E,IAAM,kBAAkB,GACpB,YAAY,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,EAAE,QAAQ,CAAC,CAAC;QACzE,IAAM,mBAAmB,GACrB,YAAY,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,EAAE,QAAQ,CAAC,CAAC;QACzE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE;YAC9B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;gBAClC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,EAAE,CAAC,EAAE,EAAE;oBACjC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,EAAE,CAAC,EAAE,EAAE;wBAIpC,IAAM,aAAa,GACf,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,mBAAmB,CAAC,CAAC,CAAC,CAAC,CAAC;wBAC3D,IAAM,aAAa,GACf,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,mBAAmB,CAAC,CAAC,CAAC,CAAC,CAAC;wBAE3D,IAAM,cAAc,GAAG,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC;wBACjD,IAAM,aAAa,GACf,IAAI,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;wBACtD,IAAM,cAAc,GAAG,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC;wBACjD,IAAM,aAAa,GACf,IAAI,CAAC,GAAG,CAAC,QAAQ,GAAG,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC;wBAErD,IAAM,OAAO,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,cAAc,EAAE,cAAc,EAAE,CAAC,CAAC,CAAC;wBAC5D,IAAM,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,aAAa,EAAE,cAAc,EAAE,CAAC,CAAC,CAAC;wBAC9D,IAAM,QAAQ,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,cAAc,EAAE,aAAa,EAAE,CAAC,CAAC,CAAC;wBAC5D,IAAM,WAAW,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,aAAa,EAAE,aAAa,EAAE,CAAC,CAAC,CAAC;wBAE9D,IAAM,OAAO,GAAG,aAAa,GAAG,cAAc,CAAC;wBAC/C,IAAM,OAAO,GAAG,aAAa,GAAG,cAAc,CAAC;wBAE/C,IAAM,GAAG,GAAG,OAAO,GAAG,CAAC,QAAQ,GAAG,OAAO,CAAC,GAAG,OAAO,CAAC;wBACrD,IAAM,MAAM,GAAG,UAAU,GAAG,CAAC,WAAW,GAAG,UAAU,CAAC,GAAG,OAAO,CAAC;wBACjE,IAAM,QAAQ,GAAG,GAAG,GAAG,CAAC,MAAM,GAAG,GAAG,CAAC,GAAG,OAAO,CAAC;wBAEhD,MAAM,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;qBAClC;iBACF;aACF;SACF;QAED,OAAO,MAAM,CAAC,QAAQ,EAAE,CAAC;IAC3B,CAAC;IAED,8CAAqB,GAArB,UACE,CAAW,EAAE,SAAiB,EAAE,QAAgB,EAChD,YAAqB;QACf,IAAA,YAAmD,EAAlD,aAAK,EAAE,iBAAS,EAAE,gBAAQ,EAAE,mBAAW,CAAY;QAC1D,IAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAU,CAAC,KAAK,EAAE,SAAS,EAAE,QAAQ,EAAE,WAAW,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAC5E,IAAM,kBAAkB,GACpB,YAAY,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,EAAE,QAAQ,CAAC,CAAC;QACzE,IAAM,mBAAmB,GACrB,YAAY,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,EAAE,QAAQ,CAAC,CAAC;QACzE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE;YAC9B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,CAAC,EAAE,EAAE;gBAClC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,EAAE,CAAC,EAAE,EAAE;oBACjC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,EAAE,CAAC,EAAE,EAAE;wBAGpC,IAAM,aAAa,GACf,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,mBAAmB,CAAC,CAAC,CAAC,CAAC,CAAC;wBAC3D,IAAM,aAAa,GACf,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,mBAAmB,CAAC,CAAC,CAAC,CAAC,CAAC;wBAC3D,IAAM,gBAAgB,GACpB,IAAI,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,EACpB,YAAY;4BACR,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC;wBACjE,IAAM,gBAAgB,GACpB,IAAI,CAAC,GAAG,CAAC,QAAQ,GAAG,CAAC,EACnB,YAAY;4BACR,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC;wBACjE,IAAM,QAAQ,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,gBAAgB,EAAE,gBAAgB,EAAE,CAAC,CAAC,CAAC;wBACjE,MAAM,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;qBAClC;iBACF;aACF;SACF;QAED,OAAO,MAAM,CAAC,QAAQ,EAAE,CAAC;IAC3B,CAAC;IAED,2CAAkB,GAAlB,UACI,CAAW,EAAE,IAAuB,EAAE,QAA2B,EACjE,eAAuB,EAAE,KAAyB,EAClD,MAA0B;QAC5B,IAAM,OAAO,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC7B,IAAM,UAAU,GAAG,IAAI,CAAC,QAAQ,EAAE,CAAC;QACnC,IAAM,cAAc,GAAG,QAAQ,CAAC,QAAQ,EAAE,CAAC;QAC3C,IAAM,WAAW,GAAG,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,IAAI,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACrE,IAAM,YAAY,GAAG,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,IAAI,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACxE,IAAM,SAAS,GAAG,IAAI,YAAY,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QAEnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACvC,SAAS,CAAC,CAAC,CAAC,GAAG,YAAY,CAAC,CAAC,GAAG,YAAY,CAAC,MAAM,CAAC;gBAChD,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,GAAG,UAAU,CAAC,MAAM,CAAC,CAAC;oBAC5C,WAAW,CAAC,CAAC,GAAG,WAAW,CAAC,MAAM,CAAC;oBACnC,IAAI,CAAC,IAAI,CACL,cAAc,CAAC,CAAC,GAAG,cAAc,CAAC,MAAM,CAAC,GAAG,eAAe,CAAC,CAAC;SAC1E;QACD,OAAO,cAAQ,CAAC,SAAS,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;IACtC,CAAC;IAED,qDAA4B,GAA5B,UACI,CAAW,EAAE,MAAc,EAAE,IAAY,EAAE,KAAa,EACxD,IAAY;QACd,IAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAU,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;QACvD,IAAM,GAAG,GAAG,MAAM,CAAC;QACnB,IAAM,IAAI,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QAEjC,2BACI,CAAS,EAAE,CAAS,EAAE,CAAS,EAAE,CAAS;YAC5C,IAAI,GAAG,GAAG,GAAG,CAAC;YACd,KAAK,IAAI,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,EAAE,CAAC,IAAI,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,EAAE;gBACpE,IAAM,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;gBAC5B,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC;aACd;YACD,OAAO,GAAG,CAAC;QACb,CAAC;QAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;YACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;gBACzC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;oBACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;wBACxC,IAAM,GAAG,GAAG,iBAAiB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;wBAC1C,IAAM,GAAG,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,GAAG,KAAK,GAAG,GAAG,EAAE,CAAC,IAAI,CAAC,CAAC;wBACpE,MAAM,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;qBAC7B;iBACF;aACF;SACF;QAED,OAAO,MAAM,CAAC,QAAQ,EAAE,CAAC;IAC3B,CAAC;IAED,oCAAW,GAAX,UACI,MAAgB,EAAE,UAAmB,EAAE,UAAkB,EACzD,IAAY;QACd,IAAM,aAAa,GAAG,UAAU,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QAChE,IAAM,SAAS,GAAG,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACzC,IAAM,SAAS,GAAG,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACzC,IAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAU,CAAC,SAAS,EAAE,UAAU,CAAC,EAAE,OAAO,CAAC,CAAC;QACjE,IAAM,OAAO,GAAG,GAAG,CAAC,QAAQ,EAAE,CAAC;QAC/B,IAAM,QAAQ,GAAG,aAAa,CAAC,QAAQ,EAAE,CAAC;QAE1C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;YAClC,IAAM,MAAM,GAAG,CAAC,GAAG,SAAS,CAAC;YAG7B,IAAM,GAAG,GAAG,IAAI,YAAY,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YAC5C,GAAG,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,MAAM,CAAC,CAAC;YAC1B,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,GAAG,CAAC,MAAM,EAAE,EAAE,KAAK,EAAE;gBAC/C,GAAG,CAAC,KAAK,CAAC,GAAG,GAAG,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,QAAQ,CAAC,MAAM,GAAG,KAAK,CAAC,CAAC;aACxD;YAED,IAAM,MAAM,GAAG,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC;YAChD,IAAM,SAAS,GAAG,CAAC,GAAG,UAAU,CAAC;YACjC,KAAK,IAAI,QAAQ,GAAG,CAAC,EAAE,QAAQ,GAAG,UAAU,EAAE,EAAE,QAAQ,EAAE;gBACxD,IAAM,CAAC,GAAG,MAAM,EAAE,CAAC;gBAGnB,OAAO,CAAC,SAAS,GAAG,QAAQ,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC;gBAE3C,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,GAAG,CAAC,MAAM,EAAE,KAAK,EAAE,EAAE;oBAC/C,IAAI,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,EAAE;wBAClB,OAAO,CAAC,SAAS,GAAG,QAAQ,CAAC,GAAG,KAAK,CAAC;wBACtC,MAAM;qBACP;iBACF;aACF;SACF;QACD,OAAO,GAAG,CAAC;IACb,CAAC;IAED,+BAAM,GAAN,UAAO,OAAiB,EAAE,KAAa,EAAE,OAAe,EAAE,QAAgB;QAExE,IAAM,GAAG,GAAG,IAAI,YAAY,CAAC,OAAO,CAAC,IAAI,GAAG,KAAK,CAAC,CAAC;QACnD,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QAEnB,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,OAAO,CAAC,IAAI,EAAE,EAAE,KAAK,EAAE;YACjD,GAAG,CAAC,KAAK,GAAG,KAAK,GAAG,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,GAAG,OAAO,CAAC;SACnD;QACD,OAAO,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE,CAAC,OAAO,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,CAAC;IAClD,CAAC;IAEO,4CAAmB,GAA3B,UACI,CAAS,EAAE,CAAS,EAAE,KAAe,EACrC,EAAoC;QACtC,IAAM,QAAQ,GACV,cAAc,CAAC,0BAA0B,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC;QAChE,IAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,QAAQ,EAAE,KAAK,CAAC,CAAC;QAC3C,IAAM,OAAO,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAC7B,IAAM,OAAO,GAAG,CAAC,CAAC,QAAQ,EAAE,CAAC;QAE7B,IAAM,cAAc,GAAG,cAAc,CAAC,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;QAC1E,IAAM,cAAc,GAAG,cAAc,CAAC,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;QAE1E,IAAM,IAAI,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC;QACxB,IAAM,IAAI,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC;gCACf,CAAC;YACR,IAAM,GAAG,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YAEjC,IAAM,IAAI,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;YAChC,cAAc,CAAC,OAAO,CAAC,UAAA,CAAC,IAAI,OAAA,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,EAAX,CAAW,CAAC,CAAC;YACzC,IAAM,MAAM,GAAG,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;YAErC,IAAM,IAAI,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;YAChC,cAAc,CAAC,OAAO,CAAC,UAAA,CAAC,IAAI,OAAA,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,EAAX,CAAW,CAAC,CAAC;YACzC,IAAM,MAAM,GAAG,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;YAErC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC;QAC1D,CAAC;QAZD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC;oBAApC,CAAC;SAYT;QACD,OAAO,MAAM,CAAC,QAAQ,EAAE,CAAC;IAC3B,CAAC;IACD,gCAAO,GAAP,cAAW,CAAC;IACd,qBAAC;AAAD,CAAC,AAhkDD,IAgkDC;AAhkDY,wCAAc;AAkkD3B,iBAAG,CAAC,eAAe,CAAC,KAAK,EAAE,cAAM,OAAA,IAAI,cAAc,EAAE,EAApB,CAAoB,EAAE,CAAC,CAAgB,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as seedrandom from 'seedrandom';\n\nimport {ENV} from '../environment';\nimport * as axis_util from '../ops/axis_util';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport * as concat_util from '../ops/concat_util';\nimport {Conv2DInfo} from '../ops/conv_util';\nimport * as ops from '../ops/ops';\nimport {buffer, tensor3d, tensor4d} from '../ops/ops';\nimport * as selu_util from '../ops/selu_util';\nimport * as erf_util from '../ops/erf_util';\n// tslint:disable-next-line:max-line-length\nimport {DataId, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D} from '../tensor';\nimport * as types from '../types';\nimport {DataType, DataTypeMap, Rank, TypedArray} from '../types';\nimport * as util from '../util';\n\nimport {BackendTimingInfo, KernelBackend} from './backend';\nimport * as backend_util from './backend_util';\n\nexport class MathBackendCPU implements KernelBackend {\n  private data = new WeakMap<DataId, DataTypeMap[DataType]>();\n  private canvas: HTMLCanvasElement;\n\n  constructor() {\n    if (typeof document !== 'undefined') {\n      this.canvas = document.createElement('canvas');\n    }\n  }\n\n  register(dataId: DataId, shape: number[], dtype: DataType): void {\n    if (this.data.has(dataId)) {\n      throw new Error(`Data buffer is already registered`);\n    }\n    this.data.set(dataId, null);\n  }\n  write(dataId: DataId, values: TypedArray): void {\n    if (values == null) {\n      throw new Error('MathBackendCPU.write(): values can not be null');\n    }\n    this.throwIfNoData(dataId);\n    this.data.set(dataId, values);\n  }\n  fromPixels(\n      pixels: ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement,\n      numChannels: number): Tensor3D {\n    if (pixels == null) {\n      throw new Error('MathBackendCPU.writePixels(): pixels can not be null');\n    }\n    let vals: Uint8ClampedArray;\n    if (pixels instanceof ImageData) {\n      vals = pixels.data;\n    } else if (pixels instanceof HTMLCanvasElement) {\n      vals = pixels.getContext('2d')\n                 .getImageData(0, 0, pixels.width, pixels.height)\n                 .data;\n    } else if (\n        pixels instanceof HTMLImageElement ||\n        pixels instanceof HTMLVideoElement) {\n      if (this.canvas == null) {\n        throw new Error(\n            'Can\\'t read pixels from HTMLImageElement outside ' +\n            'the browser.');\n      }\n      this.canvas.width = pixels.width;\n      this.canvas.height = pixels.height;\n      this.canvas.getContext('2d').drawImage(\n          pixels, 0, 0, pixels.width, pixels.height);\n      vals = this.canvas.getContext('2d')\n                 .getImageData(0, 0, pixels.width, pixels.height)\n                 .data;\n    } else {\n      throw new Error(\n          `pixels is of unknown type: ${(pixels as {}).constructor.name}`);\n    }\n    let values: Int32Array;\n    if (numChannels === 4) {\n      values = new Int32Array(vals);\n    } else {\n      const numPixels = pixels.width * pixels.height;\n      values = new Int32Array(numPixels * numChannels);\n      for (let i = 0; i < numPixels; i++) {\n        for (let channel = 0; channel < numChannels; ++channel) {\n          values[i * numChannels + channel] = vals[i * 4 + channel];\n        }\n      }\n    }\n    const outShape: [number, number, number] =\n        [pixels.height, pixels.width, numChannels];\n    return tensor3d(values, outShape, 'int32');\n  }\n  async read(dataId: DataId): Promise<TypedArray> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): TypedArray {\n    this.throwIfNoData(dataId);\n    return this.data.get(dataId);\n  }\n\n  disposeData(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      this.data.delete(dataId);\n    }\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = performance.now();\n    f();\n    const kernelMs = performance.now() - start;\n    return {kernelMs};\n  }\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true\n    };\n  }\n\n  private throwIfNoData(dataId: DataId) {\n    if (!this.data.has(dataId)) {\n      throw new Error(\n          `CPU backend: No data found for this tensor. ` +\n          `Did you change your backend in the middle of the program? ` +\n          `New backends can't use Tensors created with previous backends`);\n    }\n  }\n\n  slice<T extends Tensor>(x: T, begin: number[], size: number[]): T {\n    const buffer = ops.buffer(size, x.dtype);\n\n    for (let i = 0; i < buffer.size; ++i) {\n      const loc = buffer.indexToLoc(i);\n      const xLoc = loc.map((idx, j) => idx + begin[j]);\n      buffer.set(x.get(...xLoc), ...loc);\n    }\n    return buffer.toTensor() as T;\n  }\n\n  reverse<T extends Tensor>(x: T, axis: number[]): T {\n    const buffer = ops.buffer(x.shape, x.dtype);\n    const xBuffer = x.buffer();\n\n    for (let i = 0; i < buffer.size; i++) {\n      const outLoc = buffer.indexToLoc(i);\n      const inLoc = outLoc.slice();\n      axis.forEach(ax => inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]);\n      buffer.set(xBuffer.get(...inLoc), ...outLoc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  // Concats 2d tensors along axis=1. See comments in MathBackend.concat().\n  concat(a: Tensor2D, b: Tensor2D): Tensor2D {\n    const outShape = concat_util.computeOutShape(\n                         a.shape, b.shape, 1 /* axis */) as [number, number];\n    const buffer = ops.buffer<Rank.R2>(outShape, a.dtype);\n\n    if (a.shape[0] === 1 && b.shape[0] === 1) {\n      // Use built-in TypedArray.set() method for speed.\n      const aVals = a.dataSync();\n      const bVals = b.dataSync();\n      const vals = buffer.values;\n      vals.set(aVals, 0);\n      vals.set(bVals, a.size);\n      return buffer.toTensor();\n    }\n\n    for (let i = 0; i < outShape[0]; ++i) {\n      for (let j = 0; j < a.shape[1]; ++j) {\n        buffer.set(a.get(i, j), i, j);\n      }\n      for (let j = 0; j < b.shape[1]; ++j) {\n        buffer.set(b.get(i, j), i, j + a.shape[1]);\n      }\n    }\n    return buffer.toTensor();\n  }\n\n  neg<T extends Tensor>(x: T): T {\n    return this.multiply(ops.scalar(-1), x) as T;\n  }\n\n  add(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(\n               a, b, types.upcastType(a.dtype, b.dtype),\n               (aValue, bValue) => aValue + bValue) as Tensor;\n  }\n\n  subtract(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(\n               a, b, types.upcastType(a.dtype, b.dtype),\n               (aValue, bValue) => aValue - bValue) as Tensor;\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.pow(aValue, bValue)) as\n        T;\n  }\n\n  matMul(a: Tensor2D, b: Tensor2D, transposeA: boolean, transposeB: boolean):\n      Tensor2D {\n    const sharedDim = transposeA ? a.shape[0] : a.shape[1];\n    const leftDim = transposeA ? a.shape[1] : a.shape[0];\n    const rightDim = transposeB ? b.shape[0] : b.shape[1];\n\n    const aValues = a.dataSync();\n    const bValues = b.dataSync();\n\n    const [aOuterStep, aInnerStep] =\n      transposeA ? [1, a.strides[0]] : [a.strides[0], 1];\n    const [bOuterStep, bInnerStep] =\n      transposeB ? [b.strides[0], 1] : [1, b.strides[0]];\n\n    const aOuterEnd = leftDim * aOuterStep;\n    const bOuterEnd = rightDim * bOuterStep;\n\n    const result = new Float32Array(leftDim * rightDim);\n    let resultIndex = 0;\n\n    for (let aOuter = 0; aOuter < aOuterEnd; aOuter += aOuterStep) {\n      for (let bOuter = 0; bOuter < bOuterEnd; bOuter += bOuterStep) {\n        let aInner = aOuter;\n        let bInner = bOuter;\n        let sum = 0;\n        for (let k = 0; k < sharedDim; ++k) {\n          sum += aValues[aInner] * bValues[bInner];\n          aInner += aInnerStep;\n          bInner += bInnerStep;\n        }\n        result[resultIndex++] = sum;\n      }\n    }\n    return ops.tensor2d(result, [leftDim, rightDim]);\n  }\n\n  multiply(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(\n               a, b, types.upcastType(a.dtype, b.dtype),\n               (aValue, bValue) => aValue * bValue) as Tensor;\n  }\n\n  divide(a: Tensor, b: Tensor): Tensor {\n    let op: (a: number, b: number) => number;\n    let outputDtype: 'float32'|'int32';\n    if (a.dtype === 'int32' && b.dtype === 'int32') {\n      outputDtype = 'int32';\n      op = (a: number, b: number) => Math.floor(a / b);\n    } else {\n      outputDtype = 'float32';\n      op = (a: number, b: number) => a / b;\n    }\n    return this.broadcastedBinaryOp(a, b, outputDtype, op) as Tensor;\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n    const [outShape, reduceShape] =\n        axis_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = types.upcastType(x.dtype, 'int32');\n    const result = ops.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = result.dataSync();\n\n    const aVals = x.dataSync();\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let sum = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        sum += aVals[offset + j];\n      }\n      vals[i] = sum;\n    }\n    return result;\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    const axes = [axis];\n    axis_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n    const [outShape, reduceShape] =\n        axis_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = ops.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = result.dataSync();\n\n    const aVals = x.dataSync();\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      let minIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n          minIndex = j;\n        }\n      }\n      vals[i] = minIndex;\n    }\n    return result;\n  }\n\n  argMax(x: Tensor, axis: number): Tensor {\n    const axes = [axis];\n    axis_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n    const [outShape, reduceShape] =\n        axis_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = ops.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = result.dataSync();\n\n    const aVals = x.dataSync();\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let max = aVals[offset];\n      let maxIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value > max) {\n          max = value;\n          maxIndex = j;\n        }\n      }\n      vals[i] = maxIndex;\n    }\n    return result;\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal === bVal) ? 1 : 0;\n    });\n  }\n\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal !== bVal) ? 1 : 0;\n    });\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal < bVal) ? 1 : 0;\n    });\n  }\n\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal <= bVal) ? 1 : 0;\n    });\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal > bVal) ? 1 : 0;\n    });\n  }\n\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal >= bVal) ? 1 : 0;\n    });\n  }\n\n  logicalNot<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Int32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = values[i] ? 0 : 1;\n    }\n    return Tensor.make(x.shape, {values: newValues}, 'bool') as T;\n  }\n\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal && bVal;\n    });\n  }\n\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal || bVal;\n    });\n  }\n\n  where(condition: Tensor, a: Tensor, b: Tensor, dtype: DataType): Tensor {\n    const values = condition.dataSync();\n    const aValues = a.dataSync();\n    const bValues = b.dataSync();\n    const result = ops.zeros(a.shape, dtype);\n    const newValues = result.dataSync();\n    let index = 0;\n    const offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n        1 :\n        a.shape[1];\n\n    for (let i = 0; i < values.length; i++) {\n      for (let j = 0; j < offset; j++) {\n        if (values[i] === 1) {\n          newValues[index++] = aValues[i];\n        } else {\n          newValues[index++] = bValues[i];\n        }\n      }\n    }\n    return result;\n  }\n\n  topKValues<T extends Tensor>(x: T, k: number): Tensor1D {\n    return this.topK(x, k).values as Tensor1D;\n  }\n\n  topKIndices(x: Tensor, k: number): Tensor1D {\n    return this.topK(x, k).indices;\n  }\n\n  private topK<T extends Tensor>(x: T, k: number):\n      {values: Tensor1D, indices: Tensor1D} {\n    const values = x.dataSync();\n    const valuesAndIndices: Array<{value: number, index: number}> = [];\n    for (let i = 0; i < values.length; i++) {\n      valuesAndIndices.push({value: values[i], index: i});\n    }\n    valuesAndIndices.sort((a, b) => {\n      return b.value - a.value;\n    });\n\n    const topkValues = util.getTypedArrayFromDType(x.dtype, k);\n    const topkIndices = new Int32Array(k);\n    for (let i = 0; i < k; i++) {\n      topkValues[i] = valuesAndIndices[i].value;\n      topkIndices[i] = valuesAndIndices[i].index;\n    }\n    return {\n      values: ops.tensor1d(topkValues, x.dtype),\n      indices: ops.tensor1d(topkIndices, 'int32')\n    };\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n    const [outShape, reduceShape] =\n        axis_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = ops.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = result.dataSync();\n\n    const aVals = x.dataSync();\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[0];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n        }\n      }\n      vals[i] = min;\n    }\n    return result;\n  }\n\n  minimum(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.min(aVal, bVal));\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const rem = aVal % bVal;\n      if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n        return rem;\n      } else {\n        return (rem + bVal) % bVal;\n      }\n    });\n  }\n\n  max(x: Tensor, axes: number[]): Tensor {\n    axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n    const [outShape, reduceShape] =\n        axis_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = ops.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = result.dataSync();\n\n    const aVals = x.dataSync();\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let max = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value > max) {\n          max = value;\n        }\n      }\n      vals[i] = max;\n    }\n    return result;\n  }\n\n  maximum(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.max(aVal, bVal));\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const diff = aVal - bVal;\n      return diff * diff;\n    });\n  }\n\n  ceil<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.ceil(values[i]);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  floor<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.floor(values[i]);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  sign<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (values[i] < 0) {\n        newValues[i] = -1;\n      } else if (values[i] > 0) {\n        newValues[i] = 1;\n      } else {\n        newValues[i] = 0;\n      }\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  round<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      // The algorithm is based on banker's rounding.\n      const base = Math.floor(values[i]);\n      if (values[i] - base < 0.5) {\n        newValues[i] = Math.floor(values[i]);\n      } else if (values[i] - base > 0.5) {\n        newValues[i] = Math.ceil(values[i]);\n      } else {\n        if (base % 2.0 === 0.0) {\n          newValues[i] = base;\n        } else {\n          newValues[i] = base + 1.0;\n        }\n      }\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  exp<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.exp(values[i]);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  expm1<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.expm1(values[i]);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  log<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.log(value);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  log1p<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.log1p(value);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  sqrt<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.sqrt(value);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  rsqrt<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = 1 / Math.sqrt(value);\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  square<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  reciprocal<T extends Tensor>(x: T): T {\n    const values = x.dataSync();\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = 1 / values[i];\n    }\n    return Tensor.make(x.shape, {values: newValues}) as T;\n  }\n\n  relu<T extends Tensor>(x: T): T {\n    const res = ops.zeros(x.shape, x.dtype);\n    const resVals = res.dataSync();\n    const inVals = x.dataSync();\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.max(0, inVals[i]);\n    }\n    return res as T;\n  }\n\n  elu<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 0) {\n        resultValues[i] = v;\n      } else {\n        resultValues[i] = (Math.exp(v) - 1);\n      }\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    const resultValues = new Float32Array(y.size);\n    const values = y.dataSync();\n    const dyValues = dy.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 1) {\n        resultValues[i] = dyValues[i];\n      } else {\n        resultValues[i] = dyValues[i] * (v + 1);\n      }\n    }\n    return Tensor.make(y.shape, {values: resultValues}) as T;\n  }\n\n  selu<T extends Tensor>(x: T): T {\n    // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n    // see: https://arxiv.org/abs/1706.02515\n    const scaleAlpha = selu_util.SELU_SCALEALPHA;\n    const scale = selu_util.SELU_SCALE;\n\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 0) {\n        resultValues[i] = scale * v;\n      } else {\n        resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n      }\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  clip<T extends Tensor>(x: T, min: number, max: number): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.min(max, Math.max(min, values[i]));\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  abs<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.abs(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  int<T extends Tensor>(x: T): T {\n    const resultValues = new Int32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = values[i];\n    }\n    return Tensor.make(x.shape, {values: resultValues}, 'int32');\n  }\n\n  sigmoid<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  softplus<T extends Tensor>(x: T): T {\n    // mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n    // epsilon is the difference between 1.0 and the next representable float.\n    // For a single precision 32 bit float this should be 2^-23, see:\n    // https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n    const epsilon = 1.1920928955078125e-7;\n    const threshold = Math.log(epsilon) + 2.0;\n\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n\n    for (let i = 0; i < values.length; ++i) {\n      // Value above which exp(x) may overflow, but softplus(x) == x\n      // is within machine epsilon.\n      const tooLarge = values[i] > -threshold;\n\n      // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n      // is within machine epsilon.\n      const tooSmall = values[i] < threshold;\n\n      const expX = Math.exp(values[i]);\n      let result;\n\n      if (tooSmall) {\n        result = expX;\n      } else if (tooLarge) {\n        result = values[i];\n      } else {\n        result = Math.log(1.0 + expX);\n      }\n      resultValues[i] = result;\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  sin<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sin(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  cos<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.cos(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  tan<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.tan(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  asin<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asin(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  acos<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acos(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  atan<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atan(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  atan2<T extends Tensor>(a: T, b: T): T {\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.atan2(aValue, bValue)) as\n        T;\n  }\n\n  sinh<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sinh(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  cosh<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.cosh(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  tanh<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = util.tanh(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  asinh<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asinh(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  acosh<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acosh(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  atanh<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atanh(values[i]);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  erf<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    const p = erf_util.ERF_P;\n    const a1 = erf_util.ERF_A1;\n    const a2 = erf_util.ERF_A2;\n    const a3 = erf_util.ERF_A3;\n    const a4 = erf_util.ERF_A4;\n    const a5 = erf_util.ERF_A5;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      const t = 1.0 / (1.0 + p * v);\n      resultValues[i]\n          = 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*Math.exp(-v*v);\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  step<T extends Tensor>(x: T, alpha = 0): T {\n    const resultValues = new Float32Array(x.size);\n    const values = x.dataSync();\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      if (isNaN(value)) {\n        resultValues[i] = NaN;\n      } else {\n        resultValues[i] = value > 0 ? 1 : alpha;\n      }\n    }\n    return Tensor.make(x.shape, {values: resultValues}) as T;\n  }\n\n  conv2d(x: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const y = ops.buffer<Rank.R4>(convInfo.outShape, x.dtype);\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const xRCorner = yR * convInfo.strideHeight - padLeft;\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const xCCorner = yC * convInfo.strideWidth - padTop;\n\n            let dotProd = 0;\n            for (let wR = 0; wR < filterHeight; wR++) {\n              const xR = xRCorner + wR * dilationHeight;\n\n              if (xR < 0 || xR >= convInfo.inHeight) {\n                continue;\n              }\n\n              for (let wC = 0; wC < filterWidth; wC++) {\n                const xC = xCCorner + wC * dilationWidth;\n\n                if (xC < 0 || xC >= convInfo.inWidth) {\n                  continue;\n                }\n\n                for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                  const pixel = x.get(b, xR, xC, d1);\n                  const weight = filter.get(wR, wC, d1, d2);\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            y.set(dotProd, b, yR, yC, d2);\n          }\n        }\n      }\n    }\n    return y.toTensor();\n  }\n\n  conv2dDerInput(dy: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    const dx = ops.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2] = dx.strides;\n    const dyValues = dy.dataSync();\n    const [dyS0, dyS1, dyS2] = dy.strides;\n    const fltValues = filter.dataSync();\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {batchSize, filterHeight, filterWidth,\n           inChannels, inHeight, inWidth,\n           outChannels, outHeight, outWidth,\n           strideHeight, strideWidth} = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - leftPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax = Math.min(\n              outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - topPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax = Math.min(\n                outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                  fltS1 * (filterWidth - 1 - wC) +\n                                  fltS2 * d1;\n\n                for (let d2 = 0; d2 < outChannels; ++d2) {\n                  const pixel = dyValues[dyOffset + d2];\n                  const weight = fltValues[fltOffset + d2];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv2dDerFilter(x: Tensor4D, dy: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dW = ops.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            // Need to convolve.\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              for (let yR = yRMin; yR < yRMax; ++yR) {\n                const xR = wR + yR * strideHeight - topPad;\n                for (let yC = yCMin; yC < yCMax; ++yC) {\n                  const xC = wC + yC * strideWidth - leftPad;\n                  dotProd += x.get(b, xR, xC, d1) * dy.get(b, yR, yC, d2);\n                }\n              }\n            }\n            dW.set(dotProd, wR, wC, d1, d2);\n          }\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  depthwiseConv2D(x: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n    const y = ops.buffer<Rank.R4>(convInfo.outShape, x.dtype);\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const xRCorner = yR * convInfo.strideHeight - padLeft;\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const xCCorner = yC * convInfo.strideWidth - padTop;\n            for (let q = 0; q < chMul; ++q) {\n              let dotProd = 0;\n              for (let wR = 0; wR < filterHeight; ++wR) {\n                const xR = xRCorner + wR * dilationHeight;\n\n                if (xR < 0 || xR >= convInfo.inHeight) {\n                  continue;\n                }\n\n                for (let wC = 0; wC < filterWidth; ++wC) {\n                  const xC = xCCorner + wC * dilationWidth;\n\n                  if (xC < 0 || xC >= convInfo.inWidth) {\n                    continue;\n                  }\n\n                  const pixel = x.get(b, xR, xC, d1);\n                  const weight = filter.get(wR, wC, d1, q);\n                  dotProd += pixel * weight;\n                }\n              }\n              y.set(dotProd, b, yR, yC, d1 * chMul + q);\n            }\n          }\n        }\n      }\n    }\n\n    return y.toTensor();\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    const newShape: number[] = new Array(x.rank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = x.shape[i] * reps[i];\n    }\n    const result = ops.buffer(newShape, x.dtype);\n    const xBuf = x.buffer();\n    for (let i = 0; i < result.values.length; ++i) {\n      const newLoc = result.indexToLoc(i);\n\n      const originalLoc: number[] = new Array(x.rank);\n      for (let i = 0; i < originalLoc.length; i++) {\n        originalLoc[i] = newLoc[i] % x.shape[i];\n      }\n\n      const originalIndex = xBuf.locToIndex(originalLoc);\n\n      result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor() as T;\n  }\n\n  pad<T extends Tensor>(\n      x: T, paddings: Array<[number, number]>, constantValue: number): T {\n    const outShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n    const start = paddings.map(p => p[0]);\n    const xBuffer = x.buffer();\n    const buffer = ops.buffer(outShape, x.dtype);\n    if (constantValue !== 0) {\n      buffer.values.fill(constantValue);\n    }\n\n    for (let i = 0; i < x.size; i++) {\n      const coords = xBuffer.indexToLoc(i);\n      const outCoords = coords.map((c, i) => c + start[i]);\n      buffer.set(x.get(...coords), ...outCoords);\n    }\n    return buffer.toTensor() as T;\n  }\n\n  transpose<T extends Tensor>(x: T, perm: number[]): T {\n    const newShape: number[] = new Array(x.rank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = x.shape[perm[i]];\n    }\n    const values = x.dataSync();\n    const result = buffer(newShape, x.dtype);\n\n    const xBuf = x.buffer();\n    for (let i = 0; i < x.size; ++i) {\n      const loc = xBuf.indexToLoc(i);\n\n      // Permute location.\n      const newLoc: number[] = new Array(loc.length);\n      for (let i = 0; i < newLoc.length; i++) {\n        newLoc[i] = loc[perm[i]];\n      }\n\n      const newIndex = result.locToIndex(newLoc);\n      result.values[newIndex] = values[i];\n    }\n    return result.toTensor() as T;\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor1D, axis: number): T {\n    const newShape: number[] = x.shape.slice();\n    const indicesValues = indices.dataSync();\n    newShape[axis] = indicesValues.length;\n    const result = buffer(newShape, x.dtype);\n    const xBuf = x.buffer();\n\n    for (let i = 0; i < result.size; ++i) {\n      const newLoc = result.indexToLoc(i);\n\n      const originalLoc: number[] = newLoc.slice();\n      originalLoc[axis] = indicesValues[newLoc[axis]];\n\n      const originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor() as T;\n  }\n\n  private pool(x: Tensor4D, convInfo: Conv2DInfo, poolType: 'max'|'avg'):\n      Tensor4D {\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const y = ops.buffer<Rank.R4>(convInfo.outShape, 'float32');\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const xRCorner = yR * strideHeight - padTop;\n          const xRMin = Math.max(0, xRCorner);\n          const xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const xCCorner = yC * strideWidth - padLeft;\n            const xCMin = Math.max(0, xCCorner);\n            const xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n\n            let minMaxValue =\n                (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                                      Number.POSITIVE_INFINITY);\n            let avgValue = 0;\n            let count = 0;\n            for (let xR = xRMin; xR < xRMax; ++xR) {\n              for (let xC = xCMin; xC < xCMax; ++xC) {\n                const pixel = x.get(b, xR, xC, d);\n                if ((poolType === 'max' && pixel > minMaxValue)) {\n                  minMaxValue = pixel;\n                } else if (poolType === 'avg') {\n                  avgValue += pixel;\n                  count++;\n                }\n              }\n              if (isNaN(minMaxValue)) {\n                break;\n              }\n            }\n            y.set(\n                poolType === 'avg' ? avgValue / count : minMaxValue, b, yR, yC,\n                d);\n          }\n        }\n      }\n    }\n    return y.toTensor();\n  }\n\n  maxPool(x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return this.pool(x, convInfo, 'max');\n  }\n\n  private maxPoolPositions(x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    const maxPositions = ops.buffer<Rank.R4>(convInfo.outShape, 'int32');\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const xRCorner = yR * strideHeight - padTop;\n          const xRMin = Math.max(0, xRCorner);\n          const xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const xCCorner = yC * strideWidth - padLeft;\n            const xCMin = Math.max(0, xCCorner);\n            const xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n            let maxValue = Number.NEGATIVE_INFINITY;\n            let maxPosition = -1;\n            for (let xR = xRMin; xR < xRMax; ++xR) {\n              const wR = xR - xRCorner;\n              for (let xC = xCMin; xC < xCMax; ++xC) {\n                const wC = xC - xCCorner;\n                const pixel = x.get(b, xR, xC, d);\n                if (pixel > maxValue) {\n                  maxValue = pixel;\n                  maxPosition = wR * filterWidth + wC;\n                }\n              }\n            }\n            maxPositions.set(maxPosition, b, yR, yC, d);\n          }\n        }\n      }\n    }\n    return maxPositions.toTensor();\n  }\n\n  maxPoolBackprop(dy: Tensor4D, x: Tensor4D, y: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    const maxPositions = this.maxPoolPositions(x, convInfo);\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const padLeft = filterWidth - 1 - convInfo.padInfo.left;\n    const padTop = filterHeight - 1 - convInfo.padInfo.top;\n    const dx = ops.buffer<Rank.R4>(x.shape, 'float32');\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            // Shader code begins.\n            const dyRCorner = dxR - padTop;\n            const dyCCorner = dxC - padLeft;\n            let dotProd = 0;\n            for (let wR = 0; wR < filterHeight; ++wR) {\n              const dyR = (dyRCorner + wR) / strideHeight;\n              if (dyR < 0 || dyR >= convInfo.outHeight ||\n                  Math.floor(dyR) !== dyR) {\n                continue;\n              }\n              for (let wC = 0; wC < filterWidth; ++wC) {\n                const dyC = (dyCCorner + wC) / strideWidth;\n                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                    Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n                const maxPos = filterHeight * filterWidth - 1 -\n                    maxPositions.get(b, dyR, dyC, d);\n                const curPos = wR * filterWidth + wC;\n\n                const mask = maxPos === curPos ? 1 : 0;\n                if (mask === 0) {\n                  continue;\n                }\n\n                const pixel = dy.get(b, dyR, dyC, d);\n                dotProd += pixel * mask;\n              }\n            }\n            dx.set(dotProd, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  avgPoolBackprop(dy: Tensor4D, x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const padLeft = filterWidth - 1 - convInfo.padInfo.left;\n    const padTop = filterHeight - 1 - convInfo.padInfo.top;\n    const dx = ops.buffer<Rank.R4>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            // Shader code begins.\n            const dyRCorner = dxR - padTop;\n            const dyCCorner = dxC - padLeft;\n            let dotProd = 0;\n            for (let wR = 0; wR < filterHeight; ++wR) {\n              const dyR = (dyRCorner + wR) / strideHeight;\n              if (dyR < 0 || dyR >= convInfo.outHeight ||\n                  Math.floor(dyR) !== dyR) {\n                continue;\n              }\n              for (let wC = 0; wC < filterWidth; ++wC) {\n                const dyC = (dyCCorner + wC) / strideWidth;\n                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                    Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n\n                const pixel = dy.get(b, dyR, dyC, d);\n                dotProd += pixel;\n              }\n            }\n            dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  cast<T extends Tensor<types.Rank>>(x: T, dtype: DataType): T {\n    return backend_util.castTensor(x, dtype, this);\n  }\n\n  reshape<T extends Tensor<types.Rank>, R extends types.Rank>(\n      x: T, shape: types.ShapeMap[R]): Tensor<R> {\n    return backend_util.reshapeTensor(x, shape);\n  }\n\n  avgPool(x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return this.pool(x, convInfo, 'avg').toFloat();\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const output =\n        ops.buffer<Rank.R4>([batch, newHeight, newWidth, numChannels], x.dtype);\n\n    const effectiveInputSize: [number, number] =\n        alignCorners ? [oldHeight - 1, oldWidth - 1] : [oldHeight, oldWidth];\n    const effectiveOutputSize: [number, number] =\n        alignCorners ? [newHeight - 1, newWidth - 1] : [newHeight, newWidth];\n    for (let b = 0; b < batch; b++) {\n      for (let r = 0; r < newHeight; r++) {\n        for (let c = 0; c < newWidth; c++) {\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n\n            // Compute the fractional index of the source.\n            const sourceFracRow =\n                (effectiveInputSize[0]) * r / (effectiveOutputSize[0]);\n            const sourceFracCol =\n                (effectiveInputSize[1]) * c / (effectiveOutputSize[1]);\n\n            const sourceRowFloor = Math.floor(sourceFracRow);\n            const sourceRowCeil =\n                Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n            const sourceColFloor = Math.floor(sourceFracCol);\n            const sourceColCeil =\n                Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n\n            const topLeft = x.get(b, sourceRowFloor, sourceColFloor, d);\n            const bottomLeft = x.get(b, sourceRowCeil, sourceColFloor, d);\n            const topRight = x.get(b, sourceRowFloor, sourceColCeil, d);\n            const bottomRight = x.get(b, sourceRowCeil, sourceColCeil, d);\n\n            const rowFrac = sourceFracRow - sourceRowFloor;\n            const colFrac = sourceFracCol - sourceColFloor;\n\n            const top = topLeft + (topRight - topLeft) * colFrac;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n            const newValue = top + (bottom - top) * rowFrac;\n\n            output.set(newValue, b, r, c, d);\n          }\n        }\n      }\n    }\n\n    return output.toTensor();\n  }\n\n  resizeNearestNeighbor(\n    x: Tensor4D, newHeight: number, newWidth: number,\n    alignCorners: boolean): Tensor4D {\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const output =\n        ops.buffer<Rank.R4>([batch, newHeight, newWidth, numChannels], x.dtype);\n    const effectiveInputSize: [number, number] =\n        alignCorners ? [oldHeight - 1, oldWidth - 1] : [oldHeight, oldWidth];\n    const effectiveOutputSize: [number, number] =\n        alignCorners ? [newHeight - 1, newWidth - 1] : [newHeight, newWidth];\n    for (let b = 0; b < batch; b++) {\n      for (let r = 0; r < newHeight; r++) {\n        for (let c = 0; c < newWidth; c++) {\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n            // Compute the fractional index of the source.\n            const sourceFracRow =\n                (effectiveInputSize[0]) * r / (effectiveOutputSize[0]);\n            const sourceFracCol =\n                (effectiveInputSize[1]) * c / (effectiveOutputSize[1]);\n            const sourceNearestRow =\n              Math.min(oldHeight - 1,\n                alignCorners\n                    ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));\n            const sourceNearestCol =\n              Math.min(oldWidth - 1,\n                alignCorners\n                    ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));\n            const newValue = x.get(b, sourceNearestRow, sourceNearestCol, d);\n            output.set(newValue, b, r, c, d);\n          }\n        }\n      }\n    }\n\n    return output.toTensor();\n  }\n\n  batchNormalization(\n      x: Tensor4D, mean: Tensor4D|Tensor1D, variance: Tensor4D|Tensor1D,\n      varianceEpsilon: number, scale?: Tensor4D|Tensor1D,\n      offset?: Tensor4D|Tensor1D): Tensor4D {\n    const xValues = x.dataSync();\n    const meanValues = mean.dataSync();\n    const varianceValues = variance.dataSync();\n    const scaleValues = scale ? scale.dataSync() : new Float32Array([1]);\n    const offsetValues = offset ? offset.dataSync() : new Float32Array([0]);\n    const outValues = new Float32Array(xValues.length);\n\n    for (let i = 0; i < xValues.length; i++) {\n      outValues[i] = offsetValues[i % offsetValues.length] +\n          (xValues[i] - meanValues[i % meanValues.length]) *\n              scaleValues[i % scaleValues.length] /\n              Math.sqrt(\n                  varianceValues[i % varianceValues.length] + varianceEpsilon);\n    }\n    return tensor4d(outValues, x.shape);\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, radius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    const output = ops.buffer<Rank.R4>(x.shape, 'float32');\n    const rad = radius;\n    const maxD = output.shape[3] - 1;\n\n    function sumAcrossChannels(\n        b: number, r: number, c: number, d: number): number {\n      let sum = 0.0;\n      for (let j = Math.max(0, d - rad); j <= Math.min(d + rad, maxD); j++) {\n        const z = x.get(b, r, c, j);\n        sum += z * z;\n      }\n      return sum;\n    }\n\n    for (let b = 0; b < output.shape[0]; b++) {\n      for (let r = 0; r <= output.shape[1]; r++) {\n        for (let c = 0; c < output.shape[2]; c++) {\n          for (let d = 0; d < output.shape[3]; d++) {\n            const sum = sumAcrossChannels(b, r, c, d);\n            const val = x.get(b, r, c, d) * Math.pow(bias + alpha * sum, -beta);\n            output.set(val, b, r, c, d);\n          }\n        }\n      }\n    }\n\n    return output.toTensor();\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    const probabilities = normalized ? logits : ops.softmax(logits);\n    const batchSize = probabilities.shape[0];\n    const numEvents = probabilities.shape[1];\n    const res = ops.zeros<Rank.R2>([batchSize, numSamples], 'int32');\n    const resVals = res.dataSync();\n    const probVals = probabilities.dataSync();\n\n    for (let b = 0; b < batchSize; ++b) {\n      const offset = b * numEvents;\n      // The cdf won't include the last event. It will be implicit if no other\n      // event happened.\n      const cdf = new Float32Array(numEvents - 1);\n      cdf[0] = probVals[offset];\n      for (let event = 1; event < cdf.length; ++event) {\n        cdf[event] = cdf[event - 1] + probVals[offset + event];\n      }\n\n      const random = seedrandom.alea(seed.toString());\n      const outOffset = b * numSamples;\n      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n        const r = random();\n\n        // Assume last event happened by default.\n        resVals[outOffset + sampleId] = cdf.length;\n\n        for (let event = 0; event < cdf.length; event++) {\n          if (r < cdf[event]) {\n            resVals[outOffset + sampleId] = event;\n            break;\n          }\n        }\n      }\n    }\n    return res;\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    const res = new Float32Array(indices.size * depth);\n    res.fill(offValue);\n\n    for (let event = 0; event < indices.size; ++event) {\n      res[event * depth + indices.get(event)] = onValue;\n    }\n    return ops.tensor2d(res, [indices.size, depth]);\n  }\n\n  private broadcastedBinaryOp(\n      a: Tensor, b: Tensor, dtype: DataType,\n      op: (a: number, b: number) => number): Tensor {\n    const newShape =\n        broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const result = ops.buffer(newShape, dtype);\n    const aValues = a.dataSync();\n    const bValues = b.dataSync();\n\n    const aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n\n    const aBuf = a.buffer();\n    const bBuf = b.buffer();\n    for (let i = 0; i < result.values.length; ++i) {\n      const loc = result.indexToLoc(i);\n\n      const aLoc = loc.slice(-a.rank);\n      aBroadcastDims.forEach(d => aLoc[d] = 0);\n      const aIndex = aBuf.locToIndex(aLoc);\n\n      const bLoc = loc.slice(-b.rank);\n      bBroadcastDims.forEach(d => bLoc[d] = 0);\n      const bIndex = bBuf.locToIndex(bLoc);\n\n      result.values[i] = op(aValues[aIndex], bValues[bIndex]);\n    }\n    return result.toTensor();\n  }\n  dispose() {}\n}\n\nENV.registerBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n"]}},"hash":"c9eddba124106ff8bb5759f171441a74","cacheData":{"env":{}}}